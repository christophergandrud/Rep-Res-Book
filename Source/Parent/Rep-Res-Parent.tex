%%%%%%%%%%%%%%%
% Parent document for the book Reproducible Research with R and RStudio
% Christopher Gandrud
% Updated: 12 October 2012
%%%%%%%%%%%%%%

% Tell RStudio that weaving is to be done with the knitr package
% !Rnw weave = knitr

% Load required LaTeX packages
\documentclass[krantz1]{krantz}\usepackage{graphicx, color}
%% maxwidth is the original width if it is less than linewidth
%% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\definecolor{fgcolor}{rgb}{0.2, 0.2, 0.2}
\newcommand{\hlnumber}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlfunctioncall}[1]{\textcolor[rgb]{0.501960784313725,0,0.329411764705882}{\textbf{#1}}}%
\newcommand{\hlstring}[1]{\textcolor[rgb]{0.6,0.6,1}{#1}}%
\newcommand{\hlkeyword}[1]{\textcolor[rgb]{0,0,0}{\textbf{#1}}}%
\newcommand{\hlargument}[1]{\textcolor[rgb]{0.690196078431373,0.250980392156863,0.0196078431372549}{#1}}%
\newcommand{\hlcomment}[1]{\textcolor[rgb]{0.180392156862745,0.6,0.341176470588235}{#1}}%
\newcommand{\hlroxygencomment}[1]{\textcolor[rgb]{0.43921568627451,0.47843137254902,0.701960784313725}{#1}}%
\newcommand{\hlformalargs}[1]{\textcolor[rgb]{0.690196078431373,0.250980392156863,0.0196078431372549}{#1}}%
\newcommand{\hleqformalargs}[1]{\textcolor[rgb]{0.690196078431373,0.250980392156863,0.0196078431372549}{#1}}%
\newcommand{\hlassignement}[1]{\textcolor[rgb]{0,0,0}{\textbf{#1}}}%
\newcommand{\hlpackage}[1]{\textcolor[rgb]{0.588235294117647,0.709803921568627,0.145098039215686}{#1}}%
\newcommand{\hlslot}[1]{\textit{#1}}%
\newcommand{\hlsymbol}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlprompt}[1]{\textcolor[rgb]{0.2,0.2,0.2}{#1}}%

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}
\usepackage[authoryear]{natbib}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{subfigure}
%\usepackage{epsfig}
\usepackage{makeidx}
%\usepackage{showidx}
\usepackage{multicol}
\frenchspacing
\tolerance=5000

\usepackage{dcolumn}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{lscape}
\usepackage{url}
\usepackage{todonotes}
\usepackage[usenames,dvipsnames]{xcolor}
\usepackage{tikz}
\usetikzlibrary{trees}
\usetikzlibrary{decorations.pathmorphing}
\usetikzlibrary{shapes,arrows}
\usepackage{wrapfig}

\newcommand{\blankpage}{
\newpage
\thispagestyle{empty}
\mbox{}
\newpage
}


% Set margins on highlighted code output boxes
\setlength\fboxsep{6.25mm}

% Set knitr global options



\makeatletter
\makeatother
\makeindex

\begin{document}



% Title page
\title{Reproducible Research with R and RStudio}

\author{Christopher Gandrud}

\maketitle

% Set roman numeral page counter
\pagenumbering{roman}

% Front matter
\frontmatter

\blankpage
\blankpage
\blankpage
\blankpage

% Preface



\chapter*{Preface}

\todo[inline]{The preface is incomplete.}

\noindent This book would not have been possible without the advice and support of a great many people.

The developer and blogging community has been incredibly important for making this book possible. Foremost among among these people is Yihui Xie. He is the developer of the {\emph{knitr}} package (among others) and also an avid writer and commenter of blogs. Without him the ability to do reproducible research would be much harder and the blogging community that spreads knowledge about how to do these things would be poorer. Other great contributors to this reproducible research community include Carl Boettiger (who also developed the {\emph{knitcitations}} package), Markus Gesmann (who developed {\emph{GoogleVis}}), Jeromy Anglim and, Ramnath Vaidyanathan (who developed {\emph{Slidify}}).

The vibrant at Stack Overflow \url{http://stackoverflow.com/} and Stack Exchange \url{http://stackexchange.com/} are always very helpful for finding answers to problems that plague any coder. Importantly they makes it easy for others to find the answers to questions that have already been asked.

Thank you also to Victoria Stodden for helpful suggestions.

My students at Yonsei University were also an important part of creating this book. One of the reasons that I got interested in using many of the tools covered in this book like using {\emph{knitr}} in slideshows, was to improve my course: Introduction to Social Science Data Analysis. I tested many of the explanations and examples in this book on my students. Their feedback has been very helpful for making the book clearer and more useful.


% Table of Contents
\tableofcontents

% Convert Stylistic Conventions child documnet from Markdown to LaTex and include
\chapter*{Stylistic Conventions}\label{StylisticConventions}




\input{/git_repositories/Rep-Res-Book/Temp/StyleTemp.tex}

% Include page on installing R packages used in the book



\chapter*{Required R Packages} \label{ReqPackages}

In this book I discuss how to use a number of user-written R packages for reproducible research. Many of these packages are not included in the default R installation. They need to be installed separately. To install all of the user-written packages discussed in this book type the following code:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlfunctioncall{install.packages}(\hlstring{"apsrtable"}, 
                \hlstring{"devtools"}, 
                \hlstring{"formatR"},
                \hlstring{"ggplot2"}, 
                \hlstring{"knitr"}, 
                \hlstring{"knitcitations"}, 
                \hlstring{"markdown"}, 
                \hlstring{"openair"}, 
                \hlstring{"RCurl"},
                \hlstring{"texreg"},
                \hlstring{"tools"},                     
                \hlstring{"xtable"}, 
                \hlstring{"Zelig"})
\end{alltt}
\end{kframe}
\end{knitrout}


\noindent Once you enter this code, you may be asked to select a ``mirror"\index{mirrors, CRAN} to download the packages from. Simply select the mirror closest to you.





\listoffigures
\listoftables


\mainmatter

% Start arabic numeral page counter
\setcounter{page}{1}

% Part 1, include child documents
\part{Getting Started}

% Chapter Chapter 1 For Reproducible Research in R and RStudio
% Christopher Gandrud
% Created: 16/07/2012 05:45:03 pm CEST
% Updated: 29 October 2012




\chapter{Introducing Reproducible Research}\label{Intro}

Research is often presented in very abridged packages: slideshows, journal articles, books, or maybe even websites. These presentation documents announce a project's findings and try to convince us that the results are correct \cite[]{Mesirov2010}. It's important to remember that these documents are not the research. Especially in the computational and statistical sciences, these documents are the ``advertising". The research is the ``full software environment, code, and data that produced the results" \cite[385]{Buckheit1995,Donoho2010}. When we separate the research from its advertisement we are making it difficult for others to verify the findings by reproducing them. 

This book gives you the tools to dynamically combine your research with the presentation of your findings. The first tool is a workflow for reproducible research that weaves the principles of reproducibility throughout your entire research project, from data gathering to the statistical analysis, and the presentation of results. You will also learn how to use a number of computer tools that make this workflow possible. These tools include:

\begin{itemize}
    \item the R statistical language that will allow you to gather data and analyze it,
    \item the LaTeX and Markdown markup languages that you can use to create documents--slideshows, articles, books, and webpages--to present your findings,
    \item the {\emph{knitr}} package and other tie commands, that dynamically tie your data gathering, analysis, and presentation documents together so that they can be easily reproduced,
    \item RStudio, a program that brings all of these tools together in one place.
\end{itemize}

%%%%%%%%%%%%%% What is reproducible research? %%%%%%%%%%%%%

\section{What is reproducible research?}

Research results are replicable if there is sufficient information available for independent researchers to make the same findings using the same procedures \cite[444]{King1995}. For research that relies on experiments, this can mean a researcher not involved in the original research being able to rerun the experiment and validate that the new results match the original ones. In computational and quantitative empirical sciences results are replicable if independent researchers can recreate findings by following the procedures originally used to gather the data and run the computer code. Of course it is sometimes difficult to replicate the original data set because of limited resources.\footnote{In this book we will actually aim for replicable research, even if we don't always achieve it. New technologies make it possible to easily replicate some kinds of data sets, especially if the original data is available over the internet.} So as a next-best standard we can aim for ``really reproducible research" \cite[1226]{Peng2011}.\footnote{The idea of really reproducible computational research was originally thought of and implemented by Jon Claerbout\index{Jon Claerbout} and the Stanford Exploration Project beginning in the 1980s and early 1990s \cite[]{Fomel2009,Donoho2009}. Further seminal advances were made by Jonathan B. Buckheit and David L. Donoho who created the Wavelab library of MatLab\index{MatLab} routines for their research on wavelets in the mid-1990s \cite[]{Buckheit1995}.} In computational sciences\footnote{Reproducibility is important for both quantitative and qualitative research \cite[]{King1994}. Nonetheless, we will focus mainly on on methods for reproducibility in quantitative computational research.} this means:

\begin{quote}
    the data and code used to make a finding are available and they are sufficient for an independent researcher to recreate the finding.
\end{quote} 

In practice, research needs to be {\emph{easy}} for independent researchers to reproduce \cite[]{Ball2012}. If a study is difficult to reproduce it's more likely that no one will reproduce it. If someone does attempt to reproduce this research, it will be difficult for them to tell if any errors they find were in the original research or problems they introduced during the reproduction. In this book you will learn how to avoid these problems. 

In particular you will learn tools for dynamically ``{\emph{knitting}}"\index{knit}\footnote{Much of the reproducible computational research and literate programming literatures have traditionally used the term ``weave"\index{weave} to describe the process of combining source code and presentation documents \cite[see][101]{Knuth1992}. In the R community weave is usually used to describe the combination of source code and LaTeX documents. The term ``knit" reflects the vocabulary of the {\emph{knitr}} R package\index{knitr} and is used more generally to describe weaving with a variety of markup languages. Because of this, I use the term knit rather than weave in this book.} the data and the source code together with your presentation documents. Combined with well organized source files and clearly and completely commented code, independent researchers will be able to understand how you obtained your results. This will make your computational research easily reproducible.

%%%%%%%%%%%%%% Why should research be reproducible? %%%%%%%%%%%%%

\section{Why should research be reproducible?}

Reproducibility research is one of the main components of science. If that's not enough reason for you to make your research reproducible, consider that the tools of reproducible research also have direct benefits for you as a researcher. 

\subsection{For Science}

Replicability has been a key part of scientific enquiry from perhaps the 1200s \cite[]{Bacon1267,Nosek2012}. It has even been called the ``demarcation between science and non-science" \cite[2]{Braude1979}. Why is replication so important for scientific inquiry? 

\paragraph{Standard to judge scientific claims} 
Replication, or at the least reproducibility, opens claims to scrutiny; allowing us to keep what works and discard what doesn't. Science, according to the American Physical Society, ``is the systematic enterprise of gathering knowledge \ldots organizing and condensing that knowledge into testable laws and theories." The ``ultimate standard" for evaluating these scientific claims is whether or not the claims can be replicated \cite[]{Peng2011,Kelly2006}. Research findings cannot even really be considered ``genuine contribution[s] to human knowledge" until they have been verified through replication \cite[38]{Stodden2009}. Replication ``requires the complete and open exchange of data, procedures, and materials". Scientific conclusions that are not replicable should be abandoned or modified ``when confronted with more complete or reliable \ldots evidence".\footnote{See the American Physical Society's website at \url{http://www.aps.org/policy/statements/99_6.cfm}. See also \cite{Fomel2009}.} 

\paragraph{Avoiding effort duplication \& encouraging cumulative knowledge development} 
Not only is reproducibility crucial for evaluating scientific claims, it can also help enable the cumulative growth of future scientific knowledge \cite[]{Kelly2006,King1995}. Reproducible research cuts down on the amount of time scientists have to spend gathering data or developing procedures that have already been collected or figured out. Because researchers do not have to discover on their own things that have already been done, they can more quickly apply these data and procedures to building on established findings and developing new knowledge.

\subsection{For You}

Working to make your research reproducible does require extra upfront effort. For example, you need to put effort into learning the tools of reproducible research by doing things such as reading this book. But beyond the clear benefits for science, why should you make this effort? Using research reproducible tools can make your research process more effective and (hopefully) ultimately easier.

\paragraph{Better work habits}
Making a project reproducible from the start encourages you to use better work habits. It can spur you to more effectively plan and organize your research. It should push you to bring you data and source code up to a higher level of quality than you might if you ``thought `no one was looking'" \cite[386]{Donoho2010}. This forces you to root out errors--a ubiquitous part of computational research-earlier in the research process \cite[385]{Donoho2010}. Clear documentation also makes it easier to find errors.\footnote{Of course, it's important to keep in mind that reproducibility is ``neither necessary nor sufficient to prevent mistakes" \cite[]{Stodden2009b}.}

Reproducible research needs to be stored so that other researchers can actually access the data and source code. By taking steps to make you research accessible for others you are also making it easier for you to find your data and methods when you revise your work or begin new projects. You are avoiding personal effort duplication; allowing you to cumulatively build on your own work more effectively.

\paragraph{Better teamwork}
The steps you take to make sure an independent researcher can figure out what you have done also make it easier for your collaborators to understand your work and build on it. This applies not only to current collaborators, but also future collaborators. Bringing new members of a research team up to speed on a cumulatively growing research project is faster if they can easily understand what has been done already \cite[386]{Donoho2010}. 

\paragraph{Changes are easier}
A third person may or may not actually reproduce your research even if you make it easy for them to do so. But, {\emph{you will almost certainly reproduce parts or even all of your own research}}. Almost no actual research process is completely linear. You almost never gather data, run analyses, and present you results without going backwards to add variables, make changes to your statistical models, create new graphs, alter results tables in light of new findings, and so on. You will probably try to make these changes long after you last worked on the project and long since you remembered the details of how you did it. Whether your changes are because of journal reviewers' and conference participants' comments or you discover that new and better data has been made available since beginning the project, designing your research to be reproducible from the start makes it much easier to change things later on.  

Dynamically reproducible documents in particular can make changes much easier. Changes made to one part of a research project have a way of cascading through the other parts. For example, adding a new variable to a largely completed analysis requires gathering new data and merging it with existing data sets. If you used data imputation or matching methods you may need to rerun these models. You then have to update your main statistical analyses, and recreate the tables and graphs you used to present the results. Adding a new variable essentially forces you to reproduce large portions of your research. If when you started the project you used tools that make it easier for others to reproduce your research, you also made it easier to reproduce the work yourself. You will have taken steps to have a ``better relationship with [your] future [self]" \cite[]{Bowers2011}.

\paragraph{Higher research impact}
Reproducible research is more likely to be useful for other researchers than non-reproducible research. Useful research is cited more frequently \cite[]{Donoho2002,Vandewalle2012}. Research that is fully reproducible contains more information, i.e. more reasons to use and cite it, than presentation documents merely showing findings. Independent researchers may use the reproducible the data or code to look at other, often unanticipated, questions. When they use your work for a new purpose they will (should) cite your work. Because of this, Vandewalle et al. even argue that ``the goal of reproducible research is to have more impact with our research"  \citeyearpar[1253]{Vandewalle2007}.

A reason researchers often avoid making their research fully reproducible is that they are afraid other people will use their data and code to compete with them. I'll let Donoho et al. address this one:

\begin{quote}
    True. But competition means that strangers will read your papers, try to learn from them, cite them, and try to do even better. If you prefer obscurity, why are you publishing? \citeyearpar[16]{Donoho2009}
\end{quote}

\section{Who should read this book?}

This book is intended primarily for researchers who want to use a systematic workflow that encourages reproducibility and the practical state-of-the-art computer tools to put it into practice. This includes professional researchers, upper-level undergraduate, and graduate students working on computational data-driven projects. Hopefully, editors at academic publishers will also find the book useful for improving their ability to evaluate and edit reproducible research. 

The more researchers that use the tools of reproducibility the better. So I include enough information in the book for people who have very limited experience with these tools, including limited experience with R, LaTeX, and Markdown. They will be able to start incorporating these tools into their workflow right away. The book will also be helpful for people who already have general experience using technologies such as the R and LaTeX, but would like to know how to tie them together for reproducible research. 

\subsection{Academic Researchers}
Hopefully so far in this chapter I've convinced you that reproducible research has benefits for you as a member of the scientific community and personally as a computational researcher. This book is intended to be a practical guide for how to actually make your research reproducible. Even if you already use tools such as R and LaTeX you may not be leveraging their full potential. This book will teach you useful ways to get the most out of them as part of a reproducible research workflow.

\subsection{Students}
Upper-level undergraduate and graduate students conducting original computational research should make their research reproducible for the same reasons that professional researchers should. Forcing yourself to clearly document the steps you took will also encourage you to think more clearly about what you are doing and reinforce what you are learning. It will hopefully give you a greater appreciation of research accountability and integrity early in your careers \cite[183]{Barr2012,Ball2012}.

Even if you don't have extensive experience with computer languages, this book will teach you specific habits and tools that you can use throughout your student research and hopefully your careers. Learning these things earlier will save you considerable time and effort later.

\subsection{Instructors}
When instructors incorporate the tools of reproducible research into their assignments they not only build students' understanding of research best practice, but are also better able to evaluate and provide meaningful feedback on students' work \cite[183]{Ball2012}. This book provides a resource that you can use with students to put reproducibility into practice.

If you are teaching computational courses, you may also benefit from making your lecture material dynamically reproducible. Your slides will be easier to update for the same reasons that it is easier to update research.  Making the methods you used to create the material available to students will give them more information. Clearly documenting how you created lecture material can also pass information on to future instructors. 

\subsection{Editors}
Beyond a lack of reproducible research skills among researchers, an impediment to actually creating reproducible research is a lack of infrastructure to publish it \cite[]{Peng2011}. Hopefully, this book will be useful for editors at academic publishers who want to be better at evaluating reproducible research, editing it, and developing systems to make it more widely available. The journal {\emph{Biostatistics}} is a good example of a publication that is encouraging (actually requiring) reproducible research. From 2009 the journal  has had an editor for reproducibility that ensures replication files are available and that results can be replicated using these files \cite[]{Peng2009}. The more editors there are with the skills to work with reproducible research the more likely it is that researchers will do it.

\subsection{Private sector researchers}

Researchers in the private sector may or may not want to make their work easily reproducible outside of their organization. However, that does not mean that significant benefits cannot be gained from using the methods of reproducible research. First, even if public reproducibility is ruled out to guard proprietary information,\footnote{There are ways to enable some public reproducibility without revealing confidential information. See \cite{Vandewalle2007} for a discussion of one approach.} making your research reproducible to members of your organization can spread valuable information about how analyses were done and data was collected. This will help build your organization's knowledge and avoid effort duplication. Just as a lack of reproducibility hinders the spread of information in the scientific community, it can hinder it inside of a private organization. 

Also, the tools of reproducible research covered in this book enable you to create professional standardized reports that can be easily updated or changed when new information is available. In particular, you will learn how to create batch reports based on quantitative data.

%%%%%%%%%%%%%%%%% The Tools of Reproducible Research %%%%%%%%%%%%%%%

\section{The Tools of Reproducible Research}

This book will teach you the tools you need to make your research highly reproducible. Reproducible research involves two broad sets of tools. The first is a {\bf{reproducible research     environment}}\index{reproducible research        environment} that includes the statistical tools you need to run your analyses as well as ``the ability to automatically track the provenance of data, analyses, and results and to package them (or pointers to persistant versions of them) for redistribution". The second set of tools is a {\bf{reproducible research publisher}}\index{reproducible research publisher}, which prepares dynamic documents for presenting results and is easily linked to the reproducible research environment \cite[415]{Mesirov2010}.

In this book we will focus on learning how to use the widely available and highly flexible reproducible research environment--R/RStudio \cite[]{RLanguage,RStudioCite}. R/RStudio can be linked to numerous reproducible research publishers such as LaTeX and Markdown with Yihui Xie's {\emph{knitr}} package \citeyearpar{R-knitr}. The main tools covered in this book include:

\begin{itemize}
    \item {\bf{R}}: a programming language primarily for statistics and graphics. It can also be used for data gathering and creating presentation documents.
    
    \item {\bf{{\emph{knitr}}}}: an R package for literate programming\index{literate programming}, i.e. it allows you to combine your statistical analysis and the presentation of the results into one document. It works with R and a number of other languages such as Bash, Python, and Ruby.
    
    \item {\bf{Markup languages}}: instructions for how to format a presentation document. In this book we cover LaTeX and Markdown.  
    
    \item {\bf{RStudio}}: an integrated developer environment (IDE)\index{integrated developer  environment} for R that tightly integrates R, {\emph{knitr}}, and markup languages.
    
    \item {\bf{Cloud storage \& versioning}}: Services such as Dropbox and Github that can store data, code, and presentation files, save previous versions of these files, and make this information widely available.
    
    \item {\bf{Unix-like shell programs}}\index{Unix-like shell program}: These tools are useful for working with large research projects.\footnote{In this book I cover the Bash shell for Linux\index{Linux} and Mac as well as Windows PowerShell\index{Windows PowerShell.}} They also allow us to use command line tools including Pandoc, a program for converting documents from one markup language to another.
\end{itemize}

%%%%%%%%%%%%%%%%%%% Why use R, knitr, and RStudio for reproducible research? %%%%%%%%%%%%%%

\section{Why use R, knitr, and RStudio for reproducible research?}

\paragraph{Why R?}
Why use a statistical programming language like R for reproducible research? R has a very active development community that is constantly expanding what it is capable of. As we will see in this book this enables researchers across a wide range of disciplines to gather data and run statistical analyses. Using the {\emph{knitr}} package, you can connect your R-based analysess to presentation documents created with markup languages\index{markup language} such as LaTeX and Markdown. This allows you to dynamically and reproducibly present results in articles, slideshows, and webpages. 

The way you interact with R has benefits for reproducible research. In general you interact with R (or any other programming and markup language) by explicitly writing down your steps as source code\index{source code}. This promotes reproducibility more than your typical interactions with Graphical User Interface (GUI)\index{Graphical User Interface}\index{GUI} programs like SPSS\footnote{I know you can write scripts in statistical programs like SPSS, but doing so is not encouraged by the program's interface and you often have to learn multiple languages just to write scripts that run analyses, create graphics, and deal with matrices.} and Microsoft Word\index{Microsoft Word}. When you write R code and embed it in presentation documents created using markup languages you are forced to explicitly state the steps you took to do your research. When you do research by clicking through drop down menus in GUI programs, your steps are lost, or at least documenting them requires considerable extra effort. Also it is generally more difficult to dynamically embed your analysis in presentation documents created by GUI word processing programs in a way that will be accessible to other researchers both now and in the future. I'll come back to these points in Chapter \ref{GettingStartedRR}.

\paragraph{Why knitr?}

Literate programming\index{literate programming} is a crucial part of reproducible quantitative research.\footnote{Donald Knuth\index{Donald Knuth} coined the term literate programming in the 1970s to refer to a source file that could be both run by a computer and ``woven" with a formatted presentation document \cite[]{Knuth1992}.} Being able to directly link your analyses, your results, and the code you used to produce the results makes tracing your steps much easier. There are many different literate programming tools for a number of different programming languages. Previously, one of the most common tools for researchers using R and the LaTeX markup language was Sweave \cite[]{Leisch2002}.\index{Sweave} The package I am going to focus on in this book is newer and is called {\emph{knitr}}\index{knitr}. Why are we going to use {\emph{knitr}} in this book and not Sweave or some other tool?

The simple answer is that {\emph{knitr}} has the same capabilities as Sweave plus more. It can work with markup languages other than LaTeX\footnote{It works with LaTeX, Markdown, HTML, and reStructuredText\index{reStructuredText}. We cover the first two in this book.} and can even work with programming languages other than R. It highlights R code\index{syntax highlighting} in presentation documents making it easier for your readers to follow.\footnote{Syntax highlighting uses different colors and fonts to distinguish different types of text. For example in the PDF version of this book R commands are highlighted in \hlfunctioncall{maroon}, while character strings are in \hlstring{lavender}.} It gives you better control over the inclusion of graphics and can cache code chunks--save the output for later\index{cache code chunks}. It has the ability to understand Sweave-like syntax, so it will be easy to convert backwards to Sweave if you want to. You also have the choice to use much simpler and more straightforward syntax with {\emph{knitr}}. 

\paragraph{Why RStudio?}

\index{RStudio}Why use the RStudio integrated development environment for reproducible research? R by itself has the capabilities necessary to gather data, analyse it, and, with a little help from {\emph{knitr}} and markup languages, present results in a way that is highly reproducible. RStudio allows you to do all of these things, but simplifies many of them and allows you to navigate through them more easily. It is a happy medium between R's text-based interface and a pure GUI. 

Not only does RStudio do many of the things that R can do but more easily, it is also a very good stand alone editor for writing documents with LaTeX and Markdown. For LaTeX documents it can, for example, insert frequently used commands like \texttt{\textbackslash{}section\{\}} for numbered sections (see Chapter \ref{LatexChapter}).\footnote{If you are more comfortable with a what-you-see-is-what-you-get (WYSIWYG)\index{WYSIWYG} word processer like Microsoft Word, you might be interested in exploring Lyx\index{Lyx}. It is a WYSIWYG-like LaTeX editor that works with {\emph{knitr}}. It doesn't work with the other markup langages covered in this book. For more information see: \url{http://www.lyx.org/}.}  There are many LaTeX editors available, both open source and paid. But RStudio is currently the best program for creating reproducible LaTeX and Markdown documents. It has full syntax highlighting\index{syntax highlighting}. It's syntax highlighting can even distinguish between R code and markup commands in the same document. It can spell check LaTeX \& Markdown documents. It handles {\emph{knitr}} code chunks\index{code chunk} beautifully (see Chapter \ref{GettingStartedRKnitr}). Basically, RStudio makes it easy to create and navigate through complex documents. 

Finally, RStudio not only has tight integration with various markup languages, it also has capabilities for using other tools such as CSS, JavaScript, and a few other programming languages. It is closely integrated with the version control programs Git\index{Git} and SVN\index{SVN}. Both of these programs allow you to keep track of the changes you make to your documents (see Chapter \ref{Storing}). This is important for reproducible research since version control programs can document many of your research steps. 

\subsection{Installing the Software}\label{InstallR}

Before you read this book you should install the software. All of the software programs covered in this book are open source and can be easily downloaded for free. They are available for Windows\index{Windows}, Mac\index{Mac}, and Unix-like operating systems\index{Unix}. They should run well on most modern computers. 

You should install R before installing RStudio. You can download the programs from the following websites:

\begin{itemize}
    \item {\bf{R}}: \url{http://www.r-project.org/},
    \item {\bf{RStudio}}: \url{http://www.rstudio.com/ide/download/}.
\end{itemize}

\noindent The download webpages for these programs have comprehensive information on how to install them, so please refer to those pages for more information.

After installing R and RStudio you will probably also want to install a number of user-written packages that are covered in this book. To install all of these user-written packages, please see page \pageref{ReqPackages}.

\paragraph{Installing markup languages}

If you are planning to create LaTeX documents you need to install a LaTeX distribution\index{LaTeX distribution}. They are available for Windows, Mac, and Unix. They can be found at: \url{http://www.latex-project.org/ftp.html}. Please refer to that site for more installation information.

If you want to create Markdown documents you can separately install the {\emph{markdown}} package\index{markdown package} in R. You can do this the same way that you install any package in R, with the {\tt{install.packages}} command.\footnote{The exact command is: {\tt{install.packages("markdown")}}.} 

%%%%%%%%%%%%%% Book Overview %%%%%%%%%%%%%%

\section{Book overview}

The purpose of this book is to give you the tools that you will need to do reproducible research with R and RStudio. 

This book describes a workflow for reproducible research primarily using R and RStudio. It is designed to give you the necessary tools to use this workflow for your own research. It is not designed to be a complete introduction to R, RStudio, {\emph{knitr}}, GitHub, or any other program that is a part of this workflow. Instead it shows you how these tools can fit together to make your√ü research more reproducible. To get the most out of these individual programs I will along the way point you to other resources that cover these programs in more detail.

To that end, I can recommend a number of resources that cover more of the nitty-gritty:

\begin{itemize}
    \item Michael J. Crawley's encyclopaedic R book, appropriately titled, \textbf{The R Book} published by Wiley.
    
    \item Norman Matloff's tour through the programming language aspects of  R called \textbf{The Art of R Programming: A Tour of Statistical Design Software} published by No Starch Press.
    
    \item For an excellent introduction to the command line\index{command line} in Linux and Mac, though with pretty clear implications for Windows users if they are running PowerShell (see Chapter 2) see William E. Shotts Jr.'s book \textbf{The Linux Command Line: A Complete Introduction} also published by No Starch Press.
    
    \item The RStudio website (\url{http://www.rstudio.com/ide/docs/}) has a
  number of useful tutorials on how to use {\emph{knitr}} with LaTeX and Markdown.
\end{itemize}

That being said, my goal is for this book to be {\emph{self-sufficient}}. A reader without a detailed understanding of these programs will be able to understand and use the commands and procedures I cover in this book. While learning how to use R and the other programs I personally often encountered illustrative examples that included commands, variables, and other things that were not well explained in the texts that I was reading. This caused me to waste many hours trying to figure out, for example, what the \texttt{\$} is used for (preview: it's the component selector). I hope to save you from this wasted time by either providing a brief explanation of these possibly frustrating and mysterious conventions and/or pointing you in the direction of a good explanation.

\subsection{How to read this book}

This book gives you a workflow. It has a beginning, middle, and end. So, unlike a reference book it can and should be read linearly as it takes you through an empirical research processes from an empty folder to a completed set of documents that reproducibly showcase your findings.

That being said, readers with more experience using tools like R or LaTeX may want to skip over the nitty-gritty parts of the book that describe how to manipulate data frames or compile LaTeX documents into PDFs. Please feel free to skip these sections.

If you are experienced with R in particular you may want to skip over the first section of Chapter \ref{GettingStartedRKnitr}: Getting Started with R/RStudio. But don't skip over the whole chapter. The later parts contains important information on the {\emph{knitr}} package. 

\subsection{How this book was written}

This book practices what it preaches. It can be reproduced. I wrote the book using the programs and methods that I describe. Full documentation and source files can be found at the book's GitHub\index{GitHub} repository. Feel free to read and even use (within reason and with attribution, of course) the book's source code. You can find it at: \url{https://github.com/christophergandrud/Rep-Res-Book}. This is especially useful if you want to know how to do something in the book that I don't directly cover in the text.

\todo[inline]{During the writing of this book, the repository is private and cannot be accessed publicly.} 

\subsection{Contents overview}

The book is broken into four parts. The first part (chapters \ref{GettingStartedRR},  \ref{GettingStartedRKnitr}, and \ref{DirectoriesChapter}}) gives an overview of the reproducible research workflow as well as the general computer skills that you'll need to use this workflow. Each of the next three parts of the book guide you through the specific skills you will need for each part of the reproducible research process. The second part of the book (chapters \ref{Storing}, \ref{DataGather}, and \ref{DataClean}) covers the data gathering and file storage process. The third part (chapters \ref{StatsModel}, \ref{TablesChapter}, and \ref{FiguresChapter}) teaches you how to dynamically incorporate your statistical analysis, results figures and tables into your presentation documents. The final part (chapters \ref{LatexChapter}, \ref{LargeDocs}, and \ref{MarkdownChapter}) covers how to create reproducible presentation documents including LaTeX articles, books, slideshows and batch reports as well as Markdown webpages and slideshows.

% Chapter Chapter 2 For Reproducible Research in R and RStudio
% Christopher Gandrud
% Created: 16/07/2012 05:45:03 pm CEST
% Updated: 13 October 2012




\chapter{Getting Started with Reproducible Research}\label{GettingStartedRR}

Researchers often start thinking about making their work reproducible near the end of the research process when they write up the results or maybe even later when a journal requires their data and code be made available for publication. Or maybe even later when another researcher asks if they can use the data from a published article to reproduce the findings. By then there may be numerous versions of the data set and records of the analyses stored across multiple folders on the researcher's computer. It can be difficult and time consuming to sift through these files to create an accurate account of how the results were reached. Waiting until near the end of the research process to start thinking about reproducibility can lead to incomplete documentation that does not give an accurate account of how findings were made. Focusing on reproducibility from the beginning of the process and continuing to follow a few simple guidelines throughout your research can help solve these problems. Remember ``reproducibility is not an afterthought--it is something that must be built into the project from the beginning"\cite[386]{Donoho2010}.

This chapter first gives you a brief overview of the reproducible research process: a workflow for reproducible research. Then it covers some of the key guidelines that can help make your research more reproducible.

\section{The Big Picture: A workflow for reproducible research}

The three basic stages of a typical computational empirical research project are:

\begin{itemize}
    \item data gathering,
    \item data analysis,
    \item results presentation.
\end{itemize}

\noindent Each stage is part of the reproducible research workflow covered in this book. Tools for reproducibly gathering data are covered in Part II. Part III teaches tools for tying the data we gathered to our statistical analyses and presenting the results with tables and figures. Part IV discusses how to tie these findings into a variety of documents you can use to advertise your findings.

Instead of starting to use the individual tools of reproducible research  as soon as you learn them I recommend briefly stepping back and considering how the stages of reproducible research {\emph{tie}} together overall. This will make your workflow more coherent from the beginning and save you a lot of backtracking later on.  Figure \ref{WorkflowTies} illustrates the workflow. Notice that the arrows connecting the workflow's parts point in both directions, indicating that you should always be thinking how to make it easier to go backwards through your research, i.e. reproduce it, as well as forwards. 

Around the edges of the figure are some of the commands you will learn to make it easier to go forwards and backwards through the process. These commands tie your research together. For example, you can use API-based R packages\index{API} to gather data from the internet. You can use the \texttt{merge} command to combine data gathered from different sources into one data set. The \texttt{getURL}\index{getURL} and {\texttt{read.table}}\index{read.table} commands can be used to bring this data set into your statistical analyses. The {\emph{knitr}} package then ties your analyses into your presentation documents. This includes the code you used, the figures you created, and, with the help of tools such as the {\emph{xtable}} package, tables of results. You can even tie multiple presentation documents together. For example, you can access the same figure for use in a LaTeX article and a Markdown created website with the \texttt{includegraphics}\index{includegraphics} and \texttt{![]()}\index{![]()} commands, respectively. This helps you maintain a consistent presentation of results across multiple documents types. We'll cover these commands in detail throughout the book. See Table \ref{TableTieCommands} for a brief, but more complete overview of the main {\emph{tie commands}.\index{tie commands} 

\clearpage
\thispagestyle{plain}
\begin{landscape}
\begin{figure}[th!]
    \caption{Example Workflow \& Commands to Tie it Together}
    \label{WorkflowTies}
    \begin{center}
    
    \input{/git_repositories/Rep-Res-Book/Source/Children/Chapter2/images2/WorkFlowLinks.tex}
    \end{center}
\end{figure}
\end{landscape}

\subsection{Reproducible Theory}

An important part of the research process that I do not discuss in this book is the theoretical stage. Ideally, if you are using a deductive research design, the bulk of this work will precede and guide the data gathering and analysis stages. Just because I don't cover this stage of the research process doesn't mean that theory building can't and shouldn't be reproducible. It can in fact it may be ``the easiest part to make reproducible" \cite[1254]{Vandewalle2007}. Quotes and paraphrases from previous works in the literature obviously need to be fully cited so that others can verify that they accurately reflect the source material. For mathematically based theory, clear and complete descriptions of the proofs should be given. 

Though I don't actively cover theory replication in depth in this book, I do touch on some of the ways to incorporate proofs and citations into your presentation documents. These tools are covered in Part IV.

\section{Practical tips for reproducible research}

Before we start learning the details of the reproducible research workflow with R and RStudio it is useful to cover a few broad tips that will help you organize your research process and put these skills in perspective. The tips are:

\begin{enumerate}
    \item Document everything!,
    \item Everything is a (text) file,
    \item All files should be human readable,
    \item Explicitly tie your files together,
    \item Have a plan to organize, store, and make your files available.    
\end{enumerate}

\noindent Using these tips will help make your computational research really reproducible.

\subsection{Document everything!}

In order to reproduce your research others must be able to know what you did. You have to tell them what you did by documenting as much of your research process as possible. Ideally, you should tell your readers how you gathered your data, analyzed it, and presented the results. Documenting everthing is the key to reproducible research and lies behind all of the other tips in this chapter and tools you will learn throughout the book.

\paragraph{Document you R session info}

Before discussing the other tips its important to learn a key part of documenting with R. You should \emph{record your session info\index{session info}}. Many things in R have stayed the same since it was introduced in the early 1990s. This makes it easy for future researchers to recreate what was done in the past. However, things can change from one version of R to another. Also, the way R functions and especially how R packages are handled may vary across different operating systems, so it's important to note what system you used. Finally, you may have R set to load packages\index{packages} by default (see page \pageref{Packages} for information about packages). These packages might be necessary to run your code, but other people might not know what packages and what versions of the packages were loaded from just looking at your source code. The \texttt{sessionInfo} command in R prints a record of all of these things. The information from the session I used to create this book is:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlfunctioncall{sessionInfo}()
\end{alltt}
\begin{verbatim}
## R version 2.15.1 (2012-06-22)
## Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
## 
## locale:
## [1] en_GB.UTF-8/en_GB.UTF-8/en_GB.UTF-8/C/en_GB.UTF-8/en_GB.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets 
## [6] methods   base     
## 
## other attached packages:
## [1] knitr_0.8
## 
## loaded via a namespace (and not attached):
## [1] digest_0.5.2   evaluate_0.4.2 formatR_0.6   
## [4] plyr_1.7.1     stringr_0.6.1  tools_2.15.1
\end{verbatim}
\end{kframe}
\end{knitrout}


\noindent Chapter \ref{DirectoriesChapter} gives specific details about how to create files with dynamically included session information.

\subsection{Everything is a (text) file}

Your documentation is stored in files that include data, analysis code, the write up of results, and explanations of these files (e.g. data set codebooks, session info files, and so on). Ideally, you should use the simplest file format possible to store this information. Usually the simplest file format\footnote{Depending on the size of your data set it may not be feasible to store it as a text file. Nonetheless, text files can still be used for analysis code and presentation files.}  is the humble, but versatile, text file.\footnote{Plain text files are usually given the file extension \texttt{.txt}.}

Text files are extremely nimble. They can hold your data in, for example, comma-separated values ({\tt{.csv}}) \index{comma-separated values} format. They can contain your analysis code in {\tt{.R}} files. And they can be the basis for your presentations as markup documents like {\tt{.tex}} or {\tt{.md}}, for LaTeX and Markdown files respectively. All of these files can be opened by any program that can read text files. 

One reason reproducible research is best stored in text files is that this helps {\emph{future proof}} your research. Other file formats, like those used by Microsoft Word \index{Microsoft Word} (\texttt{.docx}) or Excel\index{Microsoft Excel} (\texttt{.xlsx}) change regularly and may not be compatible with future versions of these programs. Text files, on the other hand, can be opened by a very wide range of currently existing programs and, more likely than not, future ones as well. Even if future researchers do not have R or a LaTeX distribution, they will still be able to open your text files and, aided by frequent comments (see below), be able to understand how we conducted your research \cite[3]{Bowers2011}.

Text files are also very easy to search and manipulate with a wide range of programs--such as R and RStudio--that can find and replace text characters as well as merge and separate files. Finally, text files are easy to version and changes can be tracked using programs such as Git (see Chapter \ref{Storing}).   

\subsection{All files should be human readable}

Treat all of your research files as if someone who has not worked on the project will, in the future, try to understand them. Computer code is a way of communicating with the computer. It is `machine readable' in that the computer is able to use it to understand what you want to do.\footnote{Of course, if it does not understand it will usually give us an error message.} However, there is a very good chance that other people (or you six months in the future) will not understand what you were telling the computer. So, you need to make all of your files `human readable'. To make your source code files accessible to other people you need to {\emph{comment frequently}} \cite[3]{Bowers2011} and {\emph{format your code using a style guide}} \cite[]{Nagler1995}. For especially important pieces of code you should use {\emph{literate programming}}--where the source code and the presentation text appear in the same document. Doing this will make it very clear to others how you accomplished a piece of research.

\paragraph{Commenting}
In R everything on a line after a {\tt{\#}} hash character (also known as number, pound, or sharp) is ignored by R, but is readable to people who open the file. The hash character is a comment declaration\index{comment declaration} character. You can use the {\tt{\#}} to place comments telling other people what you are doing. Here are some examples:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcomment{# A complete comment line}
2 + 2  \hlcomment{# A comment after R code}
\end{alltt}
\begin{verbatim}
## [1] 4
\end{verbatim}
\end{kframe}
\end{knitrout}


\noindent On the first line the {\tt{\#}} is placed at the very beginning, so the entire line is treated as a comment. On the second line the {\tt{\#}} is placed after the simple equation \texttt{2 + 2}. R runs the equation as usual and finds the answer {\tt{4}}, but it ignores all of the words after the hash. 

Different languages have different comment declaration characters. In LaTeX everything after the {\tt{\%}} percent sign is treated as a comment and in markdown/HTML comments are placed inside of {\tt{\textless !-- --\textgreater}}. The hash character is used for comment declaration in shell scripts.

Nagler \citeyearpar[491]{Nagler1995} gives some advice on when and how to use comments:

\begin{itemize}
    \item write a comment before a block of code describing what the code does,
    \item comment on any line of code that is ambiguous.
\end{itemize}

\noindent In this book I follow these guidelines when displaying written code. 

He also suggests that all of your source code files should begin with a comment header. {\emph{At the least}} the header should include:

\begin{itemize}
    \item a description of what the file does,
    \item the date it was last updated,
    \item the name of the file's creator and any contributors
\end{itemize}

\noindent You may also want to include other information in the header such as what other files it depends on, what output files it produces, and what version of the programming language you are using. 

Here is an example of a minimal file header for an R source code file that creates the third figure in an article titled ``My Article":

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcomment{##################}
\hlcomment{# Source code file used to create Figure 3 in \hlstring{''}My Article\hlstring{''}}
\hlcomment{# Created by Christopher Gandrud}
\hlcomment{# Updated 15 October 2012}
\hlcomment{##################}
\end{alltt}
\end{kframe}
\end{knitrout}


\noindent Feel free to use things like the long series of hash marks above and below the header, white space, and indentations to make your comments more readable. 

\paragraph{Style guides}
In natural language writing you don't necessarily need to always follow a style guide\index{style guide}. People could probably figure out what you are saying, but it would be a lot easier for your readers if you use consistent rules. The same is true when writing computer code. It's good to follow consistent rules for formatting your code so that its easier for you and others to understand.

There are a number of R style guides. Most of them are similar to the Google R Style Guide\index{Google R Style Guide}.\footnote{See: \url{http://google-styleguide.googlecode.com/svn/trunk/google-r-style.html}.} Hadley Wickham also has a nicely presented R style guide.\footnote{You can find it at \url{https://github.com/hadley/devtools/wiki/Style}.} You may want to use the {\emph{formatR}}\index{\tt{formatR}} \cite[]{R-formatR} package to automatically reformat your code so that it is easier to read.

\paragraph{Literate programming}

For particularly important pieces of research code it may be useful to not only comment on the source file, but also display code in presentation text. For example, you may want to include key parts of the code you used for your main statistical models and an explanation of this code in an appendix following your article. This is commonly referred to as literate programming \index{literate programming} \cite[]{Knuth1992}. 

\subsection{Explicitly tie your files together}

If everything is just a text file then research projects can be thought of as individual text files that have a relationship with one another. They are tied together. A data file is used as input for an analysis file. The results of an analysis are shown and discussed in a markup file that is used to create a PDF document. Researchers often do not explicitly document the relationships between files that they used in their research. For example, the results of an analysis--a table or figure--may be copied and pasted into a presentation document. It will be very difficult for future researchers to trace the table or figure back to a particular statistical model and a particular data set. Therefore, it is important to make the links between your files explicit. 

Tie commands are the most dynamic way to explicitly link your files together.\index{tie commands} These commands instruct the computer program you are using to use information from another file. In Table \ref{TableTieCommands} I have compiled a selection of key tie commands you will learn how to use in this book. We'll discuss many more, but these are some of the most important.

\begin{table}
    \caption{A Selection of Commands for Tying Together Your Research Files}
    \label{TableTieCommands}
    \vspace{0.3cm}
    {\small{
    \begin{tabular}{p{2.5cm} c p{6cm} p{2cm}}
        \hline \vspace{0.15cm}
        Command/Package & Language & Description & Chapters for Further Information \\[0.3cm]  
        \hline \hline
        {\emph{knitr}} & R & R package with commands for tying analysis code into presentation documents including those written in LaTeX and Markdown. & Used throughout See Table \ref{ChunkOptionsTable}. \\[0.25cm]
        {\tt{read.table}} & R & Reads a table into R. You can use this to import plain-text file formated data into R. & \hfill\ref{DataGather} \\[0.25cm]
        {\tt{read.csv}} & R & Same as \texttt{read.table} with default arguments set to import \texttt{.csv} formatted data files. & \hfill\ref{DataGather} \\[0.25cm]  
        API-based packages & R & Various packages use APIs to gather data from the internet. & \hfill\ref{DataGather} \\[0.25cm]
        {\tt{merge}} & R & Merges together data frames. & \hfill\ref{DataClean} \\[0.25cm]
        {\tt{source}} & R & Runs an R source code file. & \hfill\ref{StatsModel} \\[0.25cm]
        {\tt{source\_url}} & R & From the {\emph{devtools}} package. Runs an R source code file from a secure ({\tt{https}}) url like those used by GitHub & \hfill\ref{StatsModel} \\[0.25cm]
        {\tt{print(xtable())}} & R & Combining the \texttt{print} \& \texttt{xtable} commands creates LaTeX \& HTML tables from R objects & \hfill\ref{TablesChapter} \\[0.25cm]
        {\tt{toLaTeX}} & R & Converts R objects to LaTeX & \hfill\ref{GettingStartedRR} \\[0.25cm]
        {\tt{input}} & LaTeX & Includes LaTeX files inside of other LaTeX files & \hfill\ref{LargeDocs} \\[0.25cm]
        {\tt{include}} & LaTeX & Similar to {\tt{input}}, but puts page breaks on either side of the \texttt{included}-ed text. Usually it is used for including chapters. & \hfill\ref{LargeDocs} \\[0.25cm]
        {\tt{includegraphics}} & LaTeX & Inserts a figure into a LaTeX document. & \hfill\ref{FiguresChapter} \\[0.25cm]
        \texttt{![]()} & Markdown & Inserts a figure into a Markdown document. & \hfill\ref{MarkdownChapter} \\  [0.25cm]   
        Pandoc & Shell & A Shell program for converting files from one markup language to another. Allows you to tie presentation documents together. & \hfill\ref{LargeDocs} \& \ref{MarkdownChapter} \\[0.25cm]   
        \hline 
    
    \end{tabular}
    }}
\end{table}

\subsection{Have a plan to organize, store, \& make your files available}

Finally, in order for independent researchers to reproduce your work they need to be able access the files that instruct them how to do this. Files also need to be organized so that independent researchers can figure out how they fit together. So, from the beginning of your research process you should have a plan for organizing your files and a way to make them accessible. 

One rule of thumb for organizing your research in files is to limit the amount of content any one file has. Files that contain many different operations can be very difficult to navigate, even if they have detailed comments. For example, it would be very difficult to find any particular operation in a file that contained the code used to gather the data, run all of the statistical models, and create the results figures and tables. If you have a hard time finding things in a file you created, think of the difficulties independent researchers will have! 

Because we have so many ways to link files together there is really no need to lump many different operations into one file. So, we can make our operations modular. One source code file should be used to complete one task. Breaking your operations into discrete parts will also make it easier for you and others to find errors \cite[490]{Nagler1995}.

Chapter \ref{DirectoriesChapter} discusses file organization in much more detail. Chapter \ref{Storing} teaches you a number of ways to make your files accessible through cloud computing services like Dropbox\index{Dropbox} and GitHub\index{GitHub}.


% Chapter Chapter 3 For Reproducible Research in R and RStudio
% Christopher Gandrud
% Created: 16/07/2012 05:45:03 pm CEST
% Updated: 13 October 2012




\chapter{Getting Started with R, RStudio, and knitr}\label{GettingStartedRKnitr}

If you have rarely or never used R before, the first section of this chapter gives you enough information to be able to get started and understand the R code I use in this book. For more detailed introductions on how to use R please refer to the resources I mentioned in Chapter \ref{Intro}. Experienced R users might want to skip the first section. In the second section I'll give a brief overview of RStudio. I highlight the key features of the main RStudio panel (what appears when you open RStudio) and some of its key features for reproducible research. Finally, I discuss the basics of the {\emph{knitr}} package, how to use it in R, and how it is integrated into RStudio.

%%%%%%%%%%%%% Using R
\section{Using R: the basics}

To get you started with reproducible research, we'll cover some very basic R syntax--the rules for talking to R. I cover key parts of R including:

\begin{itemize}
    \item objects \& assignment,
    \item component selection,
    \item functions and commands,
    \item arguments,
    \item the workspace and history,
    \item libraries.
\end{itemize}

Before discussing each of these in detail let's open R and look around.\footnote{Please see Chapter \ref{Intro} for instructions on how to install R.} When you open R you should get a window that looks something like Figure \ref{RBlankMain}.\footnote{This figure and almost all screenshots in this book were taken on a computer using the Mac OS 10.8 operating system.} This window is the {\bf{R console}}\index{R console}. After the startup information--information about what version of R you are using, license details, and so on--you should see a {\tt{\textgreater}}. This prompt is where you enter R code.\footnote{If you are using a Unix-like\index{Unix} system such as Ubuntu\index{Ubuntu} or Mac OS 10\index{Mac}, you can also access R via an application called the Terminal\index{Terminal}. If you have installed R on your computer you can type {\tt{r}} into the Terminal and then the {\tt{Enter}} or {\tt{Return}} key. This will begin a new R session. You know if a new R session has started if you get the same startup information is printed in the Terminal window.} To run R code that you have typed after the prompt hit the {\tt{Enter}} or {\tt{Return}} key. Now that we have a new R session\index{R session} open we can get started. 

\begin{figure}[th!]
    \caption{R Startup Console}
    \label{RBlankMain}
    \begin{center}
    \includegraphics[scale=0.4]{/git_repositories/Rep-Res-Book/Source/Children/Chapter3/images3/BlankRConsole.png}
    \end{center}
\end{figure}

\subsection{Objects}\label{Objects}

If you've read a description of R before, you will probably have seen it referred to as an `object-oriented\index{object-oriented} language'.  What are objects? Objects are like the R language's nouns. They are things, like a vector of numbers, a data set, a word, a table of results from some analysis, and so on. Saying that R is `object-oriented' just means that R is focused on doing actions to objects. We will talk about the actions--commands and functions--later in this section. For now let's create a few objects.

\paragraph{Numeric \& string objects}

Objects can have a number of different data types. Let's make two simple objects. The first is a numeric type object. The other is a character object. We can choose almost any name we want for our objects as long as it begins with an alphabetic character and does not contain spaces.\footnote{It is common for people to use either periods (\texttt{.}) or capital letters (referred to as CamelBack) separate words in object names without using spaces. For example: {\emph{new.data}} or {\emph{NewData}} rather than {\emph{new data}}.} Let's call our numeric object {\emph{Number}}. To put something into the object we use the assignment operator\index{assignment operator}\footnote{The assignment operator is sometimes also referred to as the `gets arrow`.}: {\tt{\textless -}}. Let's assign the number 10 to our {\emph{Number}} object.

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
Number <- 10
\end{alltt}
\end{kframe}
\end{knitrout}


\noindent To see the contents of our object, type its name.

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
Number
\end{alltt}
\begin{verbatim}
## [1] 10
\end{verbatim}
\end{kframe}
\end{knitrout}


\noindent Lets's briefly breakdown this output. \texttt{10} is clearly the contents of {\emph{Number}}. The double hash (\texttt{\#\#}) is included to tell you that this is output rather than R code.\footnote{The double hash is generated automatically by {\emph{knitr}}. It makes easier to copy and past code included in a presentation document by {\emph{knitr}}.} If you type the commands in your R Console, you will not get the double hash in your output. Finally, \texttt{[1]} is the row number of the object that 10 is on. Clearly our object only has one row.   

Creating a character object is very similar. The only difference is that you enclose the character string (letters in a word for example) inside of quotation marks ({\tt{""}}). To create an object called {\emph{Words}} that contains the character string ``Hello World".\label{StringObject}

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
Words <- \hlstring{"Hello World"}
\end{alltt}
\end{kframe}
\end{knitrout}



An object's type is important to keep in mind as it determines what we can do to it. For example, you cannot take the mean of a character object like the {\emph{Words}} object we created earlier:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlfunctioncall{mean}(Words)
\end{alltt}


{\ttfamily\noindent\textcolor{warningcolor}{\#\# Warning: argument is not numeric or logical: returning NA}}\begin{verbatim}
## [1] NA
\end{verbatim}
\end{kframe}
\end{knitrout}


\noindent Trying to find the mean of our {\emph{Words}} object gave us a warning message and returned the value {\tt{NA}}\index{NA}: not applicable. You can also think of {\tt{NA}} as meaning missing. To find out what type of object you have use the {\tt{class}} command. For example:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlfunctioncall{class}(Words)
\end{alltt}
\begin{verbatim}
## [1] "character"
\end{verbatim}
\end{kframe}
\end{knitrout}


\paragraph{Vector \& data frame objects}

So far we have only looked at objects with a single number or character string.\footnote{These might be called scalar objects, though in R scalars are just vectors with a length of 1.} Clearly we often want to use objects that have many strings and numbers. In R these are usually data frame\index{data frame} type objects and are roughly equivalent the data structures you would be familiar with from using a program such as Microsoft Excel. We will be using data frames extensively throughout the book. Before looking at data frames it is useful to first look at the simpler objects that make up data frames. These are called vectors. Vectors are R's ``workhorse" \cite[]{Matloff2011}. Knowing how to use vectors\index{vector} will be especially helpful when you clean up raw data in Chapter \ref{DataClean} and make tables in Chapter \ref{TablesChapter}.\footnote{If you want information about other types of R objects such as lists\index{list} and matrices\index{matrix}, Chapter 1 of Norman Matloff's book\citeyearpar{Matloff2011} is a really good place to look.} \\[0.25cm]

\noindent {\bf{Vectors}} \\[0.25cm] Vectors are the ``fundamental data type" in R \cite[]{Matloff2011}. They are simply an ordered group of numbers, character strings, and so on.\footnote{In a vector every member of the group must be of the same type. If you want an ordered group of values with different types you can use lists\index{lists}.} It may be useful to think of basically all R objects as composed of vectors. For example, data frames are basically multiple vectors of the same length--i.e. they have the same number of rows--attached together to form columns. 

Let's create a simple numeric vector containing the numbers 2.8, 2, and 14.8. To do this we will use the \texttt{c} (concatenate)\index{concatenate} function:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
NumericVect <- \hlfunctioncall{c}(2.8, 2, 14.8)

\hlcomment{# Show NumericVect's contents}
NumericVect
\end{alltt}
\begin{verbatim}
## [1]  2.8  2.0 14.8
\end{verbatim}
\end{kframe}
\end{knitrout}


Vectors of character strings are created in a similar way. The only major difference is that each character string is enclosed in quotation marks like this:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
CharacterVect <- \hlfunctioncall{c}(\hlstring{"Albania"}, \hlstring{"Botswana"}, \hlstring{"Cambodia"})

\hlcomment{# Show CharacterVect's contents}
CharacterVect
\end{alltt}
\begin{verbatim}
## [1] "Albania"  "Botswana" "Cambodia"
\end{verbatim}
\end{kframe}
\end{knitrout}


To give you a preview of what we are going to do when we start working with real data sets, lets combine the two vectors {\emph{NumericVect}} and {\emph{CharacterVect}} into a new object with the \texttt{cbind}\index{cbind} function. This function binds the two vectors together side-by-side as columns.\footnote{If you want to combine objects as if they were rows of the same column(s) use the \texttt{rbind} function.}

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
StringNumObject <- \hlfunctioncall{cbind}(CharacterVect, NumericVect)

\hlcomment{# Show StringNumObject's contents}
StringNumObject
\end{alltt}
\begin{verbatim}
##      CharacterVect NumericVect
## [1,] "Albania"     "2.8"      
## [2,] "Botswana"    "2"        
## [3,] "Cambodia"    "14.8"
\end{verbatim}
\end{kframe}
\end{knitrout}


\noindent By binding these two objects together we've created a new matrix\index{matrix} object.\footnote{Matrices are vectors with columns as well as rows.} You can see that the numbers in the {\emph{NumericVect}} column are between quotation marks. Matrices, like vectors can only have one data type. \\[0.25cm]

\noindent {\bf{Data frames}}

If we want to have an object with rows and columns and allow the columns to contain data with different types, we need to use data frames\index{data frame}. Let's use the \texttt{data.frame} command to combine the {\emph{NumericVect}} and {\emph{CharacterVect}} objects.

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
StringNumObject <- \hlfunctioncall{data.frame}(CharacterVect, NumericVect)

\hlcomment{# Display contents of StringNumObject data frame}
StringNumObject
\end{alltt}
\begin{verbatim}
##   CharacterVect NumericVect
## 1       Albania         2.8
## 2      Botswana         2.0
## 3      Cambodia        14.8
\end{verbatim}
\end{kframe}
\end{knitrout}


\noindent There are two important things to notice in this output. The first is that because we used the same name for the data frame object as the previous matrix object, R deleted the matrix object and replaced it with the data frame. This is something to keep in mind when you are creating new objects. You will also notice that the strings in the {\emph{CharacterVect}} object are no longer in quotation marks. This does not mean that they are somehow now numeric data. To prove this try to find the mean of {\emph{CharacterVect}} by running it through the \texttt{mean}\index{mean} command:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlfunctioncall{mean}(StringNumObject$ChacterVect)
\end{alltt}


{\ttfamily\noindent\textcolor{warningcolor}{\#\# Warning: argument is not numeric or logical: returning NA}}\begin{verbatim}
## [1] NA
\end{verbatim}
\end{kframe}
\end{knitrout}


\subsection{Component Selection}

The last bit of code will probably be confusing. Why do we have a dollar sign (\texttt{\$}) inbetween the name of our data frame object and the {\emph{CharcterVect}} vector? The dollar sign is called the component selector\index{component selection}.\footnote{It's also known as the element name operator.} It basically extracts a part of an object. In the previous example it extracted the {\emph{CharacterVect}} column from the {\emph{StringNumObject}} and fed it to the \texttt{mean} command, which tried (in this case unsuccessfully) to find its mean.

We can of course use the component selector to create new objects with parts of other objects. Imagine that we have the {\emph{StringNumObject}} and want an object with only the information in the numbers column. Let's use the following code:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
NewNumeric <- StringNumObject$NumericVect

\hlcomment{# Display contents of NewNumeric}
NewNumeric
\end{alltt}
\begin{verbatim}
## [1]  2.8  2.0 14.8
\end{verbatim}
\end{kframe}
\end{knitrout}


\noindent Knowing how to use the component selector will be especially useful when we discuss making tables for presentation documents in Chapter \ref{TablesChapter}.

Using the component selector can lead to long repetitive code. You have to write the object name, a dollar sign, and the component name every time you want to select a component. You can streamline your code by using commands such as \texttt{attach}\index{attach} and \texttt{with}\index{with}. For examples in this book I largely avoid using these commands, instead using the component selector. Though it creates longer code, I find it easier to follow, because it's always clear which object we are selecting a component from.

\subsection{Subscripts}

Another way to select parts of an object is to use subscripts\index{subscripts}. You have already seen subscripts in the output from our examples so far. They are denoted with square braces (\texttt{[]}). We can use subscripts to select not only columns from data frames but also rows and individual cells. As we began to see in some of the previous output, each part of a data frame has an address captured by its row and column number. We can tell R to find a part of an object by putting the row number/name, column number/name, or both in square braces. The first part denotes the rows and separated by a comma (\texttt{,}) are the columns. 

To give you an idea of how this works lets use the {\emph{cars}} data set that comes with R. Use the \texttt{head} command to get a sense of what this data set looks like.

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlfunctioncall{head}(cars)
\end{alltt}
\begin{verbatim}
##   speed dist
## 1     4    2
## 2     4   10
## 3     7    4
## 4     7   22
## 5     8   16
## 6     9   10
\end{verbatim}
\end{kframe}
\end{knitrout}


\noindent We can see a data frame with information on various cars speeds ({\emph{speed}}) and stopping distances ({\emph{dist}}). If we want to select only the third through seventh rows we can use the following subscript commands:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
cars[3:7, ]
\end{alltt}
\begin{verbatim}
##   speed dist
## 3     7    4
## 4     7   22
## 5     8   16
## 6     9   10
## 7    10   18
\end{verbatim}
\end{kframe}
\end{knitrout}


\noindent The colon (\texttt{:}) creates a sequence of whole numbers from 3 to 7. To select the fourth row of the {\emph{dist}} column we can type:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
cars[4, 2]
\end{alltt}
\begin{verbatim}
## [1] 22
\end{verbatim}
\end{kframe}
\end{knitrout}


\noindent An equivalent way to do this is:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
cars[4, \hlstring{"dist"}]
\end{alltt}
\begin{verbatim}
## [1] 22
\end{verbatim}
\end{kframe}
\end{knitrout}


\noindent Finally, we can even include a vector of column names to select:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
cars[4, \hlfunctioncall{c}(\hlstring{"speed"}, \hlstring{"dist"})]
\end{alltt}
\begin{verbatim}
##   speed dist
## 4     7   22
\end{verbatim}
\end{kframe}
\end{knitrout}


\subsection{Functions and commands}

If objects are the nouns of the R language, functions and commands\footnote{For the purposes of this book I treat the two as the same.} are the verbs. They do things to objects. Let's use the \texttt{mean} command as an example. This command takes the mean of a numeric vector object. Remember our {\emph{NumericVect}} object from before:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcomment{# Show contents of NumericVect}
NumericVect
\end{alltt}
\begin{verbatim}
## [1]  2.8  2.0 14.8
\end{verbatim}
\end{kframe}
\end{knitrout}


\noindent To find the mean of this object simply type:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlfunctioncall{mean}(x = NumericVect)
\end{alltt}
\begin{verbatim}
## [1] 6.533
\end{verbatim}
\end{kframe}
\end{knitrout}


\noindent We use the assignment operator to place a command's output into an object. For example,

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
MeanNumericVect <- \hlfunctioncall{mean}(x = NumericVect)
\end{alltt}
\end{kframe}
\end{knitrout}


\noindent Notice that we typed the command's name then enclosed the object name in parentheses immediately afterwards. This is the basic sytax that all commands use, i.e. \texttt{COMMAND(ARGUMENTS)}. If you don't want to explicitly include an argument you still need to type the parentheses after the command. 

\subsection{Arguments}

Arguments\index{argument} modify what commands do. In our most recent example we gave the \texttt{mean} command one argument (\texttt{x = NumericVect}) telling it that we wanted to find the mean of {\emph{NumericVect}}. Arguments use the \texttt{ARGUMENTLABEL = VALUE} syntax.\footnote{Note: you do not have to put spaces between the argument label and the equals sign or the equals sign and the value. However, having spaces can make your code easier for other people to read.} 

To find all of the arguments that an argument can accept look at the {\bf{Arguments}} section of the command's help file\index{help file}. To access the help file type: \texttt{?COMMAND}. For example,

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
?mean
\end{alltt}
\end{kframe}
\end{knitrout}


\noindent The help file will also tell you the default values that the arguments are set to. Clearly, you do not need to explicitly set an argument if you want to use it's default value.

You have to fairly precise with the syntax for your argument's values. Arguments for logical arguments must written as \texttt{TRUE} or \texttt{FALSE}.\footnote{They can be abbreviated \texttt{T} and \texttt{F}.} Arguments that are character strings should be in quotation marks.

Let's see how to use multiple arguments with the \texttt{round} command. This command rounds a vector of numbers. We can use the \texttt{digits} option to specify how many decimal places we want the numbers rounded to. To round the object {\emph{MeanNumericVect} to one decimal place type:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlfunctioncall{round}(x = MeanNumericVect, digits = 1)
\end{alltt}
\begin{verbatim}
## [1] 6.5
\end{verbatim}
\end{kframe}
\end{knitrout}


\noindent You can see that arguments are separated by commas. 

Some arguments do not need to be explicitly labelled. For example we could have written:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcomment{# Find mean of NumericVect}
\hlfunctioncall{mean}(NumericVect)
\end{alltt}
\begin{verbatim}
## [1] 6.533
\end{verbatim}
\end{kframe}
\end{knitrout}


\noindent R will do its best to figure out what you want and will only give up when it can't. This will generate an error message. However, to avoid any misunderstandings between yourself and R it can be good practice to label all of your arguments. This will also make your code easier for other people to read, i.e. it will be more reproducible.

Finally, you can stack arguments inside of other arguments. To have R find the mean of {\emph{NumericVect}} and round it to one decimal place use:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlfunctioncall{round}(\hlfunctioncall{mean}(NumericVect), digits = 1)
\end{alltt}
\begin{verbatim}
## [1] 6.5
\end{verbatim}
\end{kframe}
\end{knitrout}


\subsection{The Workspace \& History}

All of the objects you create become part of your workspace\index{workspace}. Use the \texttt{ls}\index{ls} command to list all of the objects in your current workspace.

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlfunctioncall{ls}()
\end{alltt}
\begin{verbatim}
## [1] "CharacterVect"   "MeanNumericVect" "NewNumeric"     
## [4] "Number"          "NumericVect"     "PackagesCited"  
## [7] "StringNumObject" "Words"
\end{verbatim}
\end{kframe}
\end{knitrout}


To save the workspace into an \texttt{.RData} file use the \texttt{save.image}\index{save.image} command. The main argument of the \texttt{save.image} command is the file path you would like the file saved into. If you don't specify the file path it will save in your current working directory (see Chapter \ref{DirectoriesChapter}). 

You should generally avoid saving your workspace. Instead, when you return to working on a project rerun the source code files. This avoids any complications caused when you use an object in your workspace that is left over from running an older version of the source code.\footnote{For example, imagine you create an object, then change the source code you used to create the object. However, there is a syntax error in the new version of the source code. The old object won't be overwritten and you will be mistakenly using the old object in future commands.} The only time when saving your workspace is very useful is when it includes an object that was computationally difficult and took a long time to create. In this case it is still useful to clean up the workspace before saving it by using the \texttt{rm} command\index{rm} to remove the other objects. For example, to remove the \texttt{CharacterVect} and \texttt{Words} objects type:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlfunctioncall{rm}(CharacterVect, Words)
\end{alltt}
\end{kframe}
\end{knitrout}


When you enter a command into R they become part of your history. To see the most recent commands in your history use the \texttt(history) command. You can also use the up and down arrows on your keyboard when your cursor is in the R console to scroll through your history.

\subsection{Installing new libraries and loading commands}\label{Packages}

Commands are stored in R libraries\index{R libraries}. R automatically loads a number of basic libraries by default. One of the great things about R is the many user-created libraries\footnote{For the latest list see: \url{http://cran.r-project.org/web/packages/available_packages_by_name.html}} that greatly expand the number of commands we can use. To install commands that do not come with base R you need to install the add-on packages\index{packages}\label{packages} that contain them. To do this use the {\tt{install.packages}}\index{install.packages} command. By default this command downloads and installs the packages from the Comprehensive R Archive Network (CRAN)\index{CRAN}. 

For the code you need to install all of the package libraries used in this book see page \pageref{ReqPackages}. When you install a package, you will likely be given a list of mirrors\index{mirrors, CRAN} from which you can download the package. Simply select the mirror closest to you.

Once you have installed a package you need to load it so that you can use its functions. Use the \texttt{library} command to load a package library. Use the following code to load the {\emph{ggplot2}} library that we use in Chapter \ref{FiguresChapter} to create figures.

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlfunctioncall{library}(ggplot2)
\end{alltt}
\end{kframe}
\end{knitrout}


\noindent Please note for the examples in this book I only specify the library a command is in if the library is not loaded by default when you start an R session. 

%%%%%%%%%%%%%%% Using RStudio
\section{Using RStudio}

As I mentioned in Chapter \ref{Intro}, RStudio is an integrated development environment for R. It provides a centralized and well organized place to do almost anything you want to do with R. As we will see later in this chapter, it is especially well integrated with literate programming tools for reproducible research. Right now let's take a quick tour of the basic RStudio window.

\paragraph{The default window}

When you first open RStudio\index{RStudio} you should see a default window that looks like Figure \ref{BlankMain}. In this figure you see three window panes\index{RStudio pane}. The large one on the left is the {\emph{Console}}. This pane functions exactly the same as the console in regular R. Other panes include the {\emph{Workspace/History}} panes, usually in the upper right-hand corner. The Workspace pane shows you all of the objects in your current workspace and some of their characteristics, like how many observations a data frame has. You can click on an object in this pane to see its contents. This is especially useful for quickly looking at a data set in much the same way that you can visually scan a Microsoft Excel spreadsheet. The History pane records all of the commands you have run. It allows you to rerun code and insert it into a source code file.

\begin{figure}[ht]
    \caption{RStudio Startup Panel}
    \label{BlankMain}
    \begin{center}
    \includegraphics[width = \textwidth]{/git_repositories/Rep-Res-Book/Source/Children/Chapter3/images3/BlankMainPanel.png}
    \end{center}
\end{figure}

In the lower right-hand corner you will see the {\emph{Files/Plots/Packages/Help}} pane. We will discuss the Files pane in more detail in Chapter \ref{DirectoriesChapter}. Basically, it allows you to see and organize your files. The Plots pane is where figures you create in R appear. This pane allows you to see all of the figures you have created in a session using the right and left arrow icons. It also lets you save the figures in a variety of formats. The Packages pane shows the packages you have installed, allows you to load individual packages by clicking on the dialog box next to them, access their manual files (click on the package name), update the packages, and even install new packages. Finally, the Help pane shows you help files. You can search for help files and search within help files using this pane.  

\paragraph{The source pane}

There is an important pane that does not show up when you open RStudio for the first time. This is the {\emph{Source}} pane. The Source pane is where you create, edit, and run your source code files. It also functions as an editor for your markup files. It is the center of reproducible research in RStudio. Let's first look at how to use the Source pane with regular R files. We will cover how to use the Source pane with literate programming file formats--e.g. R Markdown and R LaTeX--in more detail after first discussing the {\emph{knitr}} basics in the next section. 

R source code files have the file extension \texttt{.R}. You can create a new source code document, which will open a new Source pane, by going to the menu bar and clicking on \texttt{File} \textrightarrow \: \texttt{New}. In this drop down menu you have the option to create a variety of different source code documents. Select the \texttt{R Source} option. You should now see a new pane with a bar across the top that looks like the first image in Figure \ref{SourcePanes}. To run the R code you have in your source code file simply highlight it\footnote{If you are only running one line of code you don't need to highlight the code, you can simply put your cursor on that line.} and click the \texttt{Run} icon on the top bar. This sends the code to the console where it is executed. The icon to the right of \texttt{Run} simply runs the code above where you have highlighted. The \texttt{Source} icon next to this runs all of the code in the file using R's \texttt{source} command\index{source command}. The icon next to \texttt{Source} is for compiling RStudio Notebooks\index{RStudio Notebook}. We will look at RStudio Notebooks later in this chapter.

\begin{figure}[ht]
    \caption{RStudio Source Code Pane Top Bars}
    \label{SourcePanes}
    \begin{center}
    
        \begin{subfigure}
            \caption{R Source Code}
            \includegraphics[width = \textwidth]{/git_repositories/Rep-Res-Book/Source/Children/Chapter3/images3/RSourceBar.png}
        \end{subfigure}\\[0.5cm]
        
        \begin{subfigure}
            \caption{R Markdown Files}
            \includegraphics[width = \textwidth]{/git_repositories/Rep-Res-Book/Source/Children/Chapter3/images3/MarkdownSourceBar.png}
        \end{subfigure}\\[0.5cm]
        
        \begin{subfigure}
            \caption{LaTeX Markdown Files}
            \includegraphics[width = \textwidth]{/git_repositories/Rep-Res-Book/Source/Children/Chapter3/images3/LaTeXSourceBar.png}
        \end{subfigure}
        
    \end{center}
\end{figure}



%%%%%%%%%%%%% Using knitr
\section{Using knitr: the basics}

To get started with {\emph{knitr}}\index{knitr} in R or RStudio we need to learn some of the basic concepts and syntax. The concepts are the same regardless of the markup language we are knitting R code with, but much of the syntax varies by markup language.

\subsection{File extensions}

When you save a knitable file use a file extension that indicates (a) that it is knitable and (b) what markup language it is using. You can use a number of file extensions for R Markdown files including: \texttt{.Rmd} and \texttt{.Rmarkdown}. LaTeX documents that include {\emph{knitr}} code chunks are generally called R Sweave\index{R Sweave} files and have the file extension {\tt{.Rnw}}. This terminology is a little confusing. It is a holdover from {\emph{knitr}}'s main literate programming predecessor {\emph{Sweave}} \cite[]{Leisch2002}. You can also use the less confusing file extension \texttt{.Rtex}, as regular LaTeX files have the extension \texttt{.tex}. However, the syntax for \texttt{.Rtex} files is different from that used with \texttt{.Rnw} files. We'll look at this issue in more detail below.

\subsection{Code Chunks}

When you want to include R code into your markup presentation documents, place them in a code chunk\index{code chunk}. Code chunk syntax differs depending on the markup language we are using to write our documents. Let's see the syntax for R Markdown and R LaTeX files.

\paragraph{R Markdown}

In R Markdown files we begin a code chunk by writing the head: \texttt{\`\`\`\\ \{r\} }. A code chunk is closed--ended--simply with: \`\`\`\ . For example:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
```\{r\}
\hlcomment{# Example of a R Markdown code chunk}
StringNumObject <- \hlfunctioncall{cbind}(CharacterVect, NumericVect)
```
\end{alltt}
\end{kframe}
\end{knitrout}


\paragraph{R LaTeX}

There are two different ways to delimit code chunks in R LaTeX documents. One way largely emulates the established {\emph{Sweave}} syntax.\footnote{The syntax has its genesis in a literate programming tool called noweb \cite[]{Leisch2002,RamseyNoweb}.} {\emph{Knitr}} also supports files with the {\tt{.Rtex}} extension, though the code chunk syntax is different. I will cover both types of syntax for code chunks in LaTeX documents. Throughout the book I use the older and more established {\emph{Sweave}} style syntax. \\[0.25cm]

\noindent {\bf{Sweave-style}} \\[0.25cm]

Traditional Sweave-style code chunks begin with the following head: \texttt{\textless\textless \textgreater\textgreater=}. The code chunk is closed with an at sign (@).

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\textless\textless \textgreater\textgreater=
\hlcomment{# Example of a Sweave-style code chunk}
StringNumObject <- \hlfunctioncall{cbind}(CharacterVect, NumericVect)
@
\end{alltt}
\end{kframe}
\end{knitrout}

\noindent {\bf{Rtex-style}} \\[0.25cm]

Sweave-style code chunk syntax is fairly baroque compared to the Rtex-style syntax. To begin a code chunk in an \texttt{Rtex} file simply type double percent signs followed by \texttt{begin.rcode}, i.e. \texttt{\%\% begin.rcode}. To close the chunk you use double percent signs: \texttt{\%\%}. Each line in the code chunk needs to begin with a single percent sign. For example:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
%% begin.rcode
% \hlcomment{# Example of a Rtex-style code chunk}
% StringNumObject <- \hlfunctioncall{cbind}(CharacterVect, NumericVect)
%%
\end{alltt}
\end{kframe}
\end{knitrout}


\paragraph{Code chunk labels}

Each chunk has a label. When a code chunk creates a plot or the output is cached\index{cache}--stored for future use--{\emph{knitr}} uses the chunk label for the new file's name. If you do not explicitly give the chunk a label it will be assigned one like: \texttt{unnamed-chunk-1}.

To explicitly assign chunk labels in R Markdown documents place the label name inside of the braces after the \texttt{r}. If we wanted to use the label \texttt{ChunkLabel} we would simply type:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
```\{r ChunkLabel\}
\hlcomment{# Example chunk label}
```
\end{alltt}
\end{kframe}
\end{knitrout}


\noindent The same general format applies to the two types of LaTeX chunks. In Sweave-style chunks we would type: \texttt{\textless\textless ChunkLabel\textgreater\textgreater=}. In Rtex-style we use: \texttt{\%\% begin.rcode ChunkLabel}.

Try not to use spaces or periods in your label names. Also remember that chunk labels {\emph{must}} be unique.

\paragraph{Code chunk options}

There are many times when we want to change how our code chunks are knitted and presented. Maybe we only want to show the code and not the results or perhaps we don't want to show the code at all but just a figure that it produces. Maybe we want the figure to be formatted on a page in a certain way. To make these changes, and many others we can specify code chunk options\index{code chunk options}.

Like chunk labels, you specify options in the chunk head. Place them after the chunk label, separated by a comma. Chunk options are written following pretty much the same rules as regular R command arguments. They have a similar \texttt{OPTIONLABEL=VALUE} structure as arguments. The option values must be written in the same way that argument values are. Character strings need to be inside of quotation marks. The logical \texttt{TRUE} and \texttt{FALSE} operators cannot be written ``true" and ``false". For example, imagine we have a Markdown code chunk called \texttt{ChunkLabel}. If we only want to have {\emph{knitr}} include the code in our document, but not actually run it we use the option \texttt{eval=FALSE}. This option tells {\emph{knitr}} not to evaluate (run) the code chunk.

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
```\{r ChunkLabel, eval=FALSE\}
\hlcomment{# Example of a non-evaluated code chunk}
StringNumObject <- \hlfunctioncall{cbind}(CharacterVect, NumericVect)
```
\end{alltt}
\end{kframe}
\end{knitrout}


\noindent Note that all labels and code chunk options must be on the same line. Options are separated by commas. The syntax for {\emph{knitr}} options is the same regardless of the markup language. Here is the same chunk option in Rtex-style syntax:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
%% begin.rcode ChunkLabel, eval=FALSE
% \hlcomment{# Example of a non-evaluated code chunk}
% StringNumObject <- \hlfunctioncall{cbind}(CharacterVect, NumericVect)
%%
\end{alltt}
\end{kframe}
\end{knitrout}


Throughout this book we will look at a number of different code chunk options. All of the chunk options we will use in this book are listed in Table \ref{ChunkOptionsTable}. For the full list of {\emph{knitr}} options see the {\emph{knitr}} chunk options page maintained by {\emph{knitr}}'s creator Yihui Xie: \url{http://yihui.name/knitr/options#package_options}.\todo{Note: this table will be expanded as the later chapters are expanded.} 


\begin{table}
  \caption{A Selection of {\emph{knitr}} Code Chunk Options}
  \begin{center}
  \label{ChunkOptionsTable}
  \begin{tabular}{l c p{5cm}}
    \hline  
    Chunk Option Label & Type & Description \\ \hline\hline
    \texttt{eval} & Logical & Whether or not to run the chunk. \\
    \texttt{echo} & Logical & Whether or not to include the code in the presentation document. \\
    \texttt{error} & Logical & Whether or not to include errors. \\
    \texttt{engine} & Character & Set the programming language for {\emph{knitr}} to evaluate the code chunk with. \\
    \texttt{fig.align} & Character & Aligns figures. \\
    \texttt{fig.height} & Numeric & Sets figures' height. \\
    \texttt{fig.width} & Numeric & Sets figures' width. \\
    \texttt{message} & Logical & Whether or not to include message messages. \\
    \texttt{results} & Character & Whether and how to include results in the presentation document. \\
    \texttt{warning} & Logical & Whether or not to include warnings. \\
    \hline
  \end{tabular}
  \end{center}
\end{table}

\subsection{Global options}

So far we have only looked at how to set local options\index{local chunk options} in {\emph{knitr}} code chunks, i.e. options for only one specific chunk. If we want an option to apply to all of the chunks in our document we can set global chunk options\index{global chunk options}. Options are `global' in the sense that they apply to the entire document. Setting global chunk options helps us create documents that are formatted consistently without having to repetitively specify the same option every time we create a new code chunk. For example, in this book I center almost all of the the figures. Instead of using the {\tt{fig.align='center'}} option in each code chunk that creates a figure, I set the option globally.

To set a global option first create a new code chunk at the beginning of your document\footnote{In Markdown, you can put global chunk options at the very top of the document. In LaTeX they should be placed after the \texttt{\textbackslash{}begin\{document\}} command (see Chapter \ref{LatexChapter} for more information on how LaTeX documents are structured).} You will probably want to set the option {\tt{echo=FALSE}} so that {\emph{knitr}} doesn't echo the code. Inside the code chunk use {\tt{opts\_chunk\$set}}. You can set any chunk option as an argument to {\tt{opts\_chunk\$set}}. The option will be applied across your document, unless you set a different local option. 

Here is an example of how you can center align all of the figures in a Markdown document created {\emph{knitr}} code chunks. Place the following code at the beginning of the document:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
```\{r GlobalFigOpts, echo=FALSE\}
\hlcomment{# Center align all knitr figures}
opts_chunk$\hlfunctioncall{set}(fig.align=\hlstring{'center'})
```
\end{alltt}
\end{kframe}
\end{knitrout}


\subsection{knitr package options}

{\emph{Knitr}} package options\index{package options} affect how the package itself runs. For example, the {\tt{progress}} option can be set as either {\tt{TRUE}} or {\tt{FALSE}}\footnote{It's set as {\tt{TRUE}} by default.} depending on whether or not you want a progress bar\index{progress bar} to be displayed when you knit a code chunk.\footnote{The {\emph{knitr}} progress bar looks like this {\tt{|>>>>>>| 100\%}} and indicates how much of a code chunk has been run.} You can use {\tt{base.dir}} to set the directory where you want all of your figures to be saved to (see Chapter \ref{DirectoriesChapter}) or the {\tt{child.path}} option to specify where child documents are located (see Chapter \ref{LargeDocs}).

You set package options in a similar way as global chunk options with {\tt{opts\_knit\$set}}. For example, to turn off the progress bar when knitting Markdown documents include this code at the beginning of the document:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
```\{r GlobalFigOpts, echo=FALSE\}
\hlcomment{# Turn off knitr progress bar}
opts_knit$\hlfunctioncall{set}(progress=FALSE)
```
\end{alltt}
\end{kframe}
\end{knitrout}


\subsection{Hooks}

You can also set hooks\index{hooks}. Hooks come in two types: chunk hooks and output hooks. Chunk hooks\index{chunk hooks} run a function before or after a code chunk. Output hooks\index{output hooks} change how the raw output is formatted. I don't cover hooks in much detail in this book. For more information on hooks, please see Yihui Xie's webpage: \url{http://yihui.name/knitr/hooks}.

%%%%%%%%%% Knitr & RStudio
\subsection{knitr \& RStudio}

RStudio is highly integrated with {\emph{knitr}} and the markup languages knitr works with. Because of this integration it is easier to create and compile {\emph{knitr}} documents than doing so in plain R. Most of the RStudio/{\emph{knitr} features are accessed in the Source pane\index{Source pane}. The Source pane's appearance and capabilities change depending on the type of file you have open in it. RStudio uses a file's extension\index{file extension} to determine what type of file you have open.\footnote{You can manually set how you want the Source pane to act by selecting the file type using the drop down menu in the lower right-hand corner of the Source pane.} We have already seen some of the features the Source pane has for R source code files. Let's now look at how to use {\emph{knitr}} with R source code files as well as the markup formats we cover in this book: R Markdown\index{R Markdown}, and R LaTeX\index{R LaTeX}. \\[0.25cm]

\paragraph{Compiling R source code notebooks}

If you want a quick well formatted account of the code that you ran and the results that you got you can use RStudio's ``Compile Notebook"\index{notebook} capabilities. RStudio uses {\emph{knitr}} to create a standalone HTML file that includes all of the code from an R source file as well as the output. This can be useful for recording the steps you took to do an analysis. You can see an example RStudio Notebook in Figure \ref{NotebookExample}. 

If you want to create a Notebook from an open R source code file simply click the \texttt{Compile Notebook} icon in the Source pane's top bar (see Figure \ref{SourcePanes}).\footnote{Alternatively, \texttt{File} \textrightarrow \; \texttt{Compile Notebook\ldots}} Then click the \texttt{Compile} button in the window that pops up. In Figure \ref{NotebookExample} you can see near the top center right a small globe icon next to the word ``Publish". Clicking this allows you to publish your Notebook to RPubs (\url{http://www.rpubs.com/}). RPubs is a site for sharing your Notebooks over the internet. You can publish not only Notebooks, but also any {\emph{knitr}} Markdown document you compile in RStudio.

\begin{figure}
    \caption{RStudio Notebook Example}
    \label{NotebookExample}
    \begin{center}
    
\includegraphics[scale=0.4]{/git_repositories/Rep-Res-Book/Source/Children/Chapter3/images3/NotebookExample.png}
    \end{center}
\end{figure}

\paragraph{R Markdown} The second image in figure \ref{SourcePanes} is what the Source pane's top bar looks like when you have an R Markdown file open. You'll notice the familiar \texttt{Run} button for running R code. At the far right you can see a new \texttt{Chunks} drop down menu. In this menu you can select \texttt{Insert Chunk} to insert the basic syntax required for a code chunk. There is also an option to \texttt{Run Current Chunk}--i.e. the chunk where your cursor is located--\texttt{Run Next Chunk}, and \texttt{Run All} chunks. You can navigate to a specific chunk using a drop down menu on the bottom left-hand side of the Source pane (not shown). This can be very useful if you are working with a long document. To knit your file click the \texttt{Knit HTML} icon on the left side of the Source pane's top bar. This will create a knitted HTML file as well as a regular Markdown file with highlighted code, output, and figures in your R Markdown's directory. Other useful buttons in the R Markdown Source pane's top bar include the \texttt{ABC} spell check icon and \texttt{MD} icon, which gives you a Markdown syntax reference file in the Help pane.

Another useful RStudio {\emph{knitr}} integration feature is that RStudio can properly highlight both the markup language syntax and the R code in the Source pane. This makes your source code much easier to read and navigate. RStudio can also fold code chunks. This makes navigating through long documents, with long code chunks, much easier. In the first image in Figure \ref{CodeFold} you can see a small downward facing arrow at line 25. If you click this arrow the code chunk will collapse, like in the second image in Figure \ref{CodeFold}. To unfold the chunk, just click on the arrow again.

You may also notice that there are code folding arrows on lines 27 and 34 in the first image. These allow us to fold parts of the code chunk. To enable this option create a comment line with at least one hash before the comment text and at least four after it like this:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcomment{#### An RStudio Foldable Comment ####}
\end{alltt}
\end{kframe}
\end{knitrout}


\noindent You will be able to fold all of the text after this comment up until the next similarly formatted comment (or the end of the chunk).

\begin{figure}[ht!]
    \caption{Folding Code Chunks in RStudio}
    \label{CodeFold}
    \begin{center}
    \begin{subfigure}  
        \caption{Not Folded}   \includegraphics[width = \textwidth]{/git_repositories/Rep-Res-Book/Source/Children/Chapter3/images3/MarkdownNoCollapse.png}
    \end{subfigure} \\[0.5cm]
    
    \begin{subfigure}
        \caption{Folded}
      \includegraphics[width = \textwidth]{/git_repositories/Rep-Res-Book/Source/Children/Chapter3/images3/MarkdownCollapse.png}        
    \end{subfigure}
    \end{center}
\end{figure}

\paragraph{R LaTeX}

You can see in the final image in Figure \ref{SourcePanes} that many of the Source pane options for R LaTeX files are the same as R Markdown files. The key differences being that there is a \texttt{Compile PDF} icon instead of \texttt{Knit HTML}. Clicking this icon knits the file and creates a PDF file in your R LaTeX file's directory. There is also a \texttt{Format} icon instead of \texttt{MD}. This actually inserts LaTeX formatting commands into your document for things such as section headings and bullet lists. These commands can be very tedious to type out by hand.


\paragraph{Change default .Rnw knitter}

By default RStudio is set up to use Sweave\index{Sweave} for compiling LaTeX documents. To use {\emph{knitr}} instead of Sweave to knit \texttt{.Rnw} files in RStudio you should click on \texttt{Tools} in the RStudio menu bar then click on \texttt{Options} window\index{RStudio Options window}. Once the {\bf{Options}} window opens, click on the \texttt{Sweave} button. Select \texttt{knitr} from the drop down menu for ``Weave files using:". Finally, click \texttt{Apply}. 

\subsection{knitr \& R}

As {\emph{knitr}} is a regular R package, you can of course knit documents in R (or using the console in RStudio). All of the {\emph{knitr}} syntax in your markup document is the same as before, but instead of clicking a {\tt{Compile PDF}} or {\tt{knit HTML}} button use the {\tt{knit}} command. To knit an example Markdown file {\emph{Example.Rmd}} you first set us the \texttt{setwd} command to set the working directory (for more details see Chapter \ref{DirectoriesChapter}) to the the folder where the {\emph{Example.Rmd}} file is located. In this example it is located on the desktop.\footnote{Using the directory name {\tt{$\sim$/Desktop/}} is for Mac computers. Please use alternative syntax discussed in Chapter \ref{DirectoriesChapter} on other types of systems.}

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlfunctioncall{setwd}(\hlstring{"~/Desktop/"})
\end{alltt}
\end{kframe}
\end{knitrout}


\noindent Then you knit the file:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlfunctioncall{knit}(input = \hlstring{"Example.Rmd"}, output = \hlstring{"Example.md"})
\end{alltt}
\end{kframe}
\end{knitrout}


\noindent You use the same steps for all other knitable document types. Note that if you do not specify the output file, {\emph{knitr}} will determine what the file name and extension should be. In this example it would come up with the same name and location as you gave it.

In this example, using the {\emph{knit}} command only creates a Markdown file and not an HTML file, as clicking the RStudio {\tt{knit HTML}} did. Likewise, if you use {\tt{knit}} on a {\tt{.Rnw}} file you will only end up with a basic LaTeX {\tt{.tex}} file and not a compiled PDF. To convert the Markdown file into HTML you need to further run the {\tt{.md}} file through the {\tt{markdownToHTML}} command from the {\emph{markdown}} package, i.e.

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlfunctioncall{mardownToHTML}(file = \hlstring{"Example.md"}, output = \hlstring{"Example.html"})
\end{alltt}
\end{kframe}
\end{knitrout}


\noindent This is a bit tedious. Luckily, there is a command in the {\emph{knitr}} package that combines \texttt{markdownToHTML} and \texttt{knit}. It is called \texttt{knit2html}. You use it like this:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlfunctioncall{knit2html}(file = \hlstring{"Example.Rmd"}, output = \hlstring{"Example.html"})
\end{alltt}
\end{kframe}
\end{knitrout}


\noindent If we want to compile a {\tt{.tex}} file in R we run it through the {\tt{texi2pdf}} command in the {\emph{tools}} package. This package will run both LaTeX and \BibTeX to create a PDF with a bibliography (see Chapter \ref{LatexChapter} for more details on using \BibTeX for bibliographies). Here is a {\tt{texi2pdf}} example:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcomment{# Load tools package}
\hlfunctioncall{library}(tools)

\hlcomment{# Compile pdf}
\hlfunctioncall{texi2pdf}(file = \hlstring{"Example.tex"})
\end{alltt}
\end{kframe}
\end{knitrout}


\noindent Just like with \texttt{knit2html}, you can simplify this process by using the \texttt{knit2pdf} command to compile a PDF file from a \texttt{.Rnw} or \texttt{.Rtex} document.


% Chapter Chapter 4 For Reproducible Research in R and RStudio
% Christopher Gandrud
% Created: 16/07/2012 05:45:03 pm CEST
% Updated: 14 October 2012




\chapter{Getting Started with File Management}\label{DirectoriesChapter}

Careful file management is crucial for reproducible research. Remember two of the guidelines from Chapter \ref{GettingStartedRR}:

\begin{itemize}
    \item Explicitly tie your files together,
    \item Have a plan to organize, store, and make your files available. 
\end{itemize}

Apart from the times when you have an email exchange (or even meet in person) with someone interested in reproducing your research, the main information independent researchers have about the procedures you used will be stored across many files: data files, analysis files, and presentation files. If these files are well organized and the links tying them together are clear, replication will be much easier. File management is also important for you as a researcher, because if your files are well organized you will be able to more easily make changes, collaborate with others, and so on. 

Using tools such as R, {\emph{knitr}, and markup languages like LaTeX requires fairly detailed knowledge of where files are stored in your computer. Handling files reproducibly may require you to use command line tools to access and organize your files. R and Unix-like shell programs\index{Unix-like shell program} allow you to control files--creating, deleting, moving them--in powerful and really reproducible ways. By typing these commands you are documenting every step you took. This is a major advantage over graphical user interface-type systems where you organize files by clicking and dragging them with the cursor. However, text commands require you to know your files' specific addresses--their file paths. 

In this chapter we discuss how a reproducible research project may be organized and cover the basics of file path naming conventions\index{file path naming conventions} in Unix, Mac, and Windows systems. We then learn how to organize them with RStudio Projects\index{RStudio Projects}. Finally, we will cover some basic R and Unix-like shell commands for manipulating files as well as how to navigate through files in RStudio in the {\bf{Files}} pane. The skills you will learn in this chapter will be heavily used in the next chapter (Chapter \ref{Storing}) and throughout the book.

In this chapter we work with locally stored files\index{locally stored}, i.e. files stored on your computer. In the next chapter we will discuss various ways to store and access files remotely stored in the cloud\index{cloud storage}.


\section{File paths \& naming conventions}

All of the operating systems\index{operating systems} covered in this book organize files in hierarchical directories\index{directories}, also know as file trees. To a large extent, `directories' can be thought of as the folders you usually see on your Windows or Mac desktop.\footnote{To simplify things, I use the terms `directory' and `folder' interchangeably in this book.} They are called `hierarchical' because directories are located inside of other directories, as in Figure \ref{ExampleTree}. 

\subsection{Root directories}

A root directory\index{root directory} is the first level in a disk, such as a hard drive. It is the root out of which the file tree `grows'. All other directories are subdirectories\index{subdirectory} of the root directory.\footnote{On Windows computers you can have multiple root directories, one for each storage device or partition of a storage device.}


On Windows computers the root directory is given a drive letter assignment\index{drive letter assignment}. If you use Windows regularly you will most likely be familiar with the \texttt{C:\textbackslash{}} used to denote the C partition of the the hardrive. This is a root directory. On Unix-like systems, including Mac computers. The root directory is simply labeled \texttt{/} with nothing before it.

\subsection{Subdirectories \& parent directories}

You will probably not store all of your files  the root directory. This would get very messy. Instead you will likely store your files in subdirectories of the root directory. Inside of these subdirectories may be further subdirectories and so on.  Directories inside of other directories are child directories or subdirectories of a parent directory\index{parent directory}.

On Windows computers separate subdirectories are indicated with a back slash (\textbackslash{}). For example if we have a folder called {\emph{Data}} inside of a folder called {\emph{ExampleProject}} which is located in the C root directory it has the address \texttt{C:\textbackslash{}ExampleProject\textbackslash{}Data}.\footnote{For more information on Windows file path names see this helpful website: \url{http://msdn.microsoft.com/en-us/library/windows/desktop/aa365247(v=vs.85).aspx}} When you type Windows file paths into R you need to use two backslashes rather than one: \texttt{C:\textbackslash{}\textbackslash{}ExampleProject\textbackslash{}\textbackslash{}Data}. This is because the \texttt{\textbackslash{}} is an escape character\index{escape character} in R.\footnote{As we will see in Part IV, it is also a LaTeX escape character.} Escape characters tell R to interpret the next character or sequence of characters differently. For example, on page \pageref{TSVEscape} you'll see how \texttt{\textbackslash{}t} can be interpreted by R as a tab. To neutralize the escape character simply add another escape character, i.e. escape the escape character. In R this simply means using a double backslash: \texttt{\textbackslash{}\textbackslash{}}. Another option for writing Windows file names is to use one forward slash (\texttt{/}).  

On Unix-like systems, including Mac computers, directories are indicated with a forward slash (\texttt{/}). The file path of the {\emph{Data}} file on a Unix-like system would be: \texttt{/ExampleProject/Data}

In the book I switch between the two file system naming conventions to expose you to both.

\subsection{Spaces in directory \& file names}

It is generally good practice to avoid putting spaces in your file and directory names. For example, I called the example project parent directory ``ExampleProject" rather than ``Example Project". Spaces in file and directory names can sometimes create problems for compter programs trying to read the file path. It may believe that the space indicates that the path name has ended. To make multi-word names easily readable without using spaces, adopt a convention such as CamelBack\index{CamelBack}. In CamelBack new words are indicated with capital letters, while all other letters are lower case. For example, ``ExampleProject".

\subsection{Working directories}

When you use R and markup languages it is important to keep in mind what your current working directory is\index{working directory}. The working directory is the directory where the program automatically looks for files and other directories. It is also where it will save files. Later in this chapter we will cover commands for handling the working directory.

\section{Organizing your research project}

Figure \ref{ExampleTree} gives an example of how the files in a simple reproducible research project could be organized. The project's main parent directory is called {\emph{ExampleProject}}. Inside this directory are three subdirectories: a data gathering directory, an analysis directory, and a presentation directory. Each of these directories contains further subdirectories and files. The {\emph{Presentation}} directory for example contains subdirectories for files that present the findings in article, slideshow, and website formats.

\clearpage
\thispagestyle{plain}
\begin{landscape}
\begin{figure}[th!]
    \caption{Example Research Project File Tree}
    \label{ExampleTree}
    \begin{center}
    
    \input{/git_repositories/Rep-Res-Book/Source/Children/Chapter4/images4/ExampleFilePath.tex}
    \end{center}
\end{figure}
\end{landscape}

\begin{wrapfigure}{r}{0.4\textwidth}
    \caption{An Example RStudio Project Menu}
    \label{ProjectMenu}
    \begin{center}
    \includegraphics[width=0.3\textwidth]{/git_repositories/Rep-Res-Book/Source/Children/Chapter4/images4/ProjectMenu.png}
    \end{center}
\end{wrapfigure}


In addition to the main subdirectories of {\emph{ExampleProject}} you will probably notice a file called {\emph{README.md}} The {\emph{README.md}} file\index{README file} gives an overview of all the files in the project. It should briefly describe the project including things like its title, author(s), topic, any copyright information, and so on. It should also indicate how the folders in the project are organized and give instruction for how to reproduce the project. The README file should be in the main project folder--in our example this is called {\emph{ExampleProject}}--so that it is easy to find. If you are storing your project as a GitHub\index{GitHub} repository (see Chapter \ref{Storing}) and the file is called \texttt{README} its contents will automatically be displayed on the repository's main page. If it is written using Markdown, it will also be properly formatted.

It is good practice to dynamically include the system information for the R session you used to create the project. To do this you can write your README file with R Markdown (see Chapter \ref{LargeDocs}). Simply include the \texttt{sessionInfo()} command in a code chunk in the R Markdown document. If you knit this file immediately after knitting your presentation document it will record the information for that session.

You can also dynamically include session info in a LaTeX document. To do this simply use the {\tt{toLatex}} command in a code chunk. The code chunk should have the option \texttt{results='asis'}. The code is:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlfunctioncall{toLatex}(\hlfunctioncall{sessionInfo}())
\end{alltt}
\end{kframe}
\end{knitrout}


%% Make file discussion?

\section{Setting directories as RStudio Projects}

If you are using RStudio, you may want to organize your files as Projects\index{RStudio Projects}. You can turn a normal directory into an RStudio Project by clicking on \texttt{Project} in the RStudio menu bar and selecting \texttt{Create Project\ldots}. A new window will pop up. Select the option \texttt{Existing Directory}. Find the directory you want to turn into an RStudio Project by clicking on the \texttt{Browse} button. Finally, select \texttt{Create Project}. You will also notice in the Create Project pop up window that you can build new project directories and create a project from a directory already under version control\index{version control} (we'll do this in Chapter \ref{Storing}). When you create a new project you will see that RStudio has put a file with the extension \texttt{.Rproj} into the directory.

Making your research project directories RStudio Projects is useful for a number of reasons:

\begin{itemize}
    \item the project is listed in RStudio's Project menu where it can be opened easily (see Figure \ref{ProjectMenu}).
    \item when you open the \textttt{.Rproj} file RStudio automatically sets the working directory to the project's directory and loads the project workspace, history, and source code files you were last working on.
    \item you can set project specific options like whether PDF presentation documents should be compiled with Sweave or {\emph{knitr}}.
    \item when you close the project your R workspace and history are saved in the project directory,
    \item it helps you version control your files
\end{itemize}

%%%%%%%%%%%%%%% File Manipulation
\section{R file manipulation commands}

R has an a range of commands for handling and navigating through files. Including these commands in your source code files allows you to more easily replicate your actions.

\paragraph{{\tt{getwd}}}\index{getwd}

To find out what current working directory R use the \texttt{getwed} command:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlfunctioncall{getwd}()
\end{alltt}
\begin{verbatim}
## [1] "/git_repositories/Rep-Res-Book/Source/Children/Chapter4"
\end{verbatim}
\end{kframe}
\end{knitrout}


\noindent The example here shows you the current working directory that was used while knitting this chapter.

\paragraph{{\tt{list.files}}}\index{list.files}

Use the \texttt{list.files} command to see all of the files and subdirectories in the current working directory. You can list the files in other directories too by adding the directory path as an argument to the command.  

\paragraph{{\tt{setwd}}}\index{setwd}

The {\tt{setwd}} command sets the current working directory\index{working directory}. For example, if we are on a Mac or other Unix-like computer we can set the working directory to the {\emph{GatherSource}} directory in our Example Project (see Figure \ref{ExampleTree}) like this

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlfunctioncall{setwd}(\hlstring{"/ExampleProject/Data/GatherSource"})
\end{alltt}
\end{kframe}
\end{knitrout}


\noindent Now R will automatically look in the {\emph{GatherSource}} folder for files and will save new files into this folder, unless we explicitly tell it to do otherwise.

\paragraph{{\tt{dir.create}}}\index{dir.create}

Sometimes you may want to create a new directory. You can use the {\tt{dir.create}} command to do this.\footnote{Note: you will need the correct system permissions to be able to do this.} For example to create a {\emph{ExampleProject}} file in the root C directory on a Windows computer type:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlfunctioncall{dir.create}(\hlstring{"C:\textbackslash{}\textbackslash{}ExampleProject"})
\end{alltt}
\end{kframe}
\end{knitrout}


\paragraph{{\tt{file.create}}}\index{file.create}

Similarly, you can create a new blank file with the \texttt{file.create} command. To add a blank R source code file called {\emph{SourceCode.R}} to the {\emph{ExampleProject}} directory on the C drive use:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlfunctioncall{file.create}(\hlstring{"C:\textbackslash{}\textbackslash{}ExampleProject\textbackslash{}\textbackslash{}SourceCode.R"})
\end{alltt}
\end{kframe}
\end{knitrout}


\paragraph{{\tt{unlink}}}\index{unlink}

Finally, you can use the {\tt{unlink}} command to delete files and directories. 

\section{Unix-like shell commands for file management} 

\todo[inline]{The remainder of this chapter is incomplete.}

\begin{wrapfigure}{r}{0.5\textwidth}
    \caption{The RStudio Files Pane} %\\[0.25cm]
    \label{FilesPane}
        \begin{center}    
        \includegraphics[width=0.45\textwidth]{/git_repositories/Rep-Res-Book/Source/Children/Chapter4/images4/RStudioFiles.png}
        \end{center}
\end{wrapfigure}

Though this book is mostly focused on using R for reproducible research it can be useful to use a Unix-like shell program\index{Unix-like shell program} to manipulate files in large projects. A command line shell program is simply a program that allows you to type commands to interact with your computer's operating system. We will especially return to shell commands in the next chapter when we discuss GitHub and near the end of the book when we look at make files\index{make file} for compiling large documents, and batch reports\index{batch reports} as well as the command line program Pandoc (Chapter \ref{LargeDocs}). The syntax discussed here is also similar to the used in command line git (Chapter \ref{Storing}) and Pandoc (chapter \ref{LargeDocs} and \ref{MarkdownChapter}). We don't have enough space to fully introduce shell programs. For good introductions for Unix and Mac OS 10 computers see William E. Shotts Jr.'s book on the Linux command-line\cite[]{ShottsJr2012}. For Windows users, Microsoft maintains a tutorial on Windows PowerShell at \url{http://technet.microsoft.com/en-us/library/hh848793}.

The one piece of general instruction I will give now is to highlight an important difference in the syntax between R and shell commands. In shell commands you don't need to put parentheses around your arguments. For example if I want to change my working directory to my Mac Desktop in a shell using the {\tt{cd}} command I simply type:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{verbatim}
cd /Users/Me/Desktop
\end{verbatim}
\end{kframe}
\end{knitrout}


\paragraph{{\tt{cd}}}\index{cd}

As we just saw, to change the working directory in the shell just use the {\tt{cd}} (change directory) command.

\paragraph{{\tt{rm}}}

The {\tt{rm}}\index{rm} command is similar to R's {\tt{unlink}} command. It removes (deletes) files or directories.

As we saw in Chapter \ref{GettingStartedRKnitr}, R also has an \texttt{rm} command. It is different because it removes objects from your R workspace rather than files from your working directory.

\section{File navigation in RStudio}

The RStudio {\bf{Files}} pane allows us to navigate and do some basic file manipulation. Figure \ref{FilesPane} shows us what this pane looks like.



% Part 2, include child documents
\part{Data Gathering and Storage}

% Chapter Chapter 5 For Reproducible Research in R and RStudio
% Christopher Gandrud
% Created: 16/07/2012 05:45:03 pm CEST
% Updated: 13 October 2012




\chapter{Storing, Collaborating, Accessing Files, Versioning}\label{Storing}

In addition to being well organized, your research files need to be accessible for other researchers to be able to reproduce your findings. A useful way to make your files accessible is to store them on a cloud storage service\footnote{These services store your data on remote servers} \cite[see][]{Howe2012}. This chapter describes in detail two different cloud storage services--Dropbox and GitHub--that you can use to make your research files easily accessible to others. Not only do these services enable others to reproduce your research, they also have a number of benefits for your research workflow. Researchers often face a number of data management issues that, beyond making their research difficult to reproduce, can make doing the initial research difficult.

First, there is the problem of \textbf{storing} the data so that it is protected against computer failure--virus infections, spilling coffee on your laptop, and so on. Storing data locally--on your computer--or on a flash drive is generally more prone to loss than on remote servers in the cloud.

Second, we may work on a project with different computers and other devices. For example, we may use a computer at work to run computationally intensive analysis, while editing our presentation document on an tablet computer while riding the train to the office. So, we need to be able to \textbf{access} our files from multiple devices while in different locations. We often need a way for our \textbf{collaborators} to access and edit research files as well.

Finally, we almost never create a data set or write a paper perfectly all at once. We may make changes and then realize that we liked an earlier version, or parts of an earlier version better. This is a particularly important issue in data management where we may transform our data in unintended ways and want to go back to earlier versions. Also, when working on a collaborative project, one of the authors may accidentally delete something in a file that another author needed. To deal with these issues we need to store our data in a system that has \textbf{version control}. Version control systems keep track of changes we make to our files and allows us to access previous versions if we want to.

You can solve all of these problems in a couple of different ways using free or low cost cloud-based storage formats. In this chapter we will learn how to use Dropbox and GitHub for research file:

\begin{itemize}
    \item storage,
    \item accessing,
    \item collaboration,
    \item version control.
\end{itemize}

\section{Saving data in reproducible formats}

Before getting into the details of cloud-based data storage for all of our research files, lets consider what type of formats you should actually save your data in\index{data file formats}. A key issue for reproducibility is that others be able to not only get ahold of the exact data you used in your analysis, but be able to understand and use the data now and in the future. Some file formats make this easier than others.

In general, for small to moderately-sized data sets\footnote{I don't cover methods for storing and handling very large data sets--with high hundreds of thousands and more observations. For information on large data and R, not just storage, one place to look is this blog post by from RDataMining: \url{http://rdatamining.wordpress.com/2012/05/06/online-resources-for-handling-big-data-and-parallel-computing-in-r/} (posted 6 May 2012).} a plain-text format like comma-separated values\index{comma-separated values} (\texttt{.csv}) or tab-separated values\index{tab-separated values}\footnote{Sometimes this format is called tab-delimited values\index{tab-delimited values}.} (\texttt{.tsv}) can be a good way to store your data. These formats simply store a data set as a text file. A row in the data set is a line in the text file. Data is separated into columns with commas or tabs, respectively. These formats are not dependent on a specific program. Any program that can open text files can open them including a wide variety of statistical programs other than R. This helps future proof your research. Version control systems that track changes to text, like GitHub--are also very effective version control systems with these types of files. 

To save data in a plain-text format with R use the \texttt{write.table} command\index{write.table}. For example, to save a data frame called {\emph{Data}} as a CSV file called {\emph{MainData.csv}} in our example {\emph{DataFiles}} directory (see Figure \ref{ExampleTree}):

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlfunctioncall{write.table}(Data, \hlstring{"/ExampleProject/Data/DataFiles/MainData.csv"},
                 sep = \hlstring{","})
\end{alltt}
\end{kframe}
\end{knitrout}


\noindent The \texttt{sep = ","} argument specifies that we want to use a comma to separate the values. For CSV files you can use a modified version of this command called \texttt{write.csv}\index{write.csv}. This command simply makes it so that you don't have to write \texttt{sep = ","}. 

If you want to save your data with rows separated by tabs, rather than commas, simply set the argument \texttt{sep = "\textbackslash{}t"} and the file extension to \texttt{.tsv}.\label{TSVEscape}

R is also able to save data in a wide variety of other file formats, mostly through the {\emph{foreign}} package (see Chapter \ref{DataGather}). These formats may be less future proof than simple text-formatted data files.

\section{Storing your files in the cloud}

In this book we'll cover two (largely) free cloud storage services that allow you to store, access, collaborate on, and version control your research files. These services are Dropbox and GitHub.\footnote{Dropbox provides a minimum amount of storage for free, above which they charge a fee. GitHub lets you create publicly accessible repositories--kind of like project folders--for free, but they charge for private repositories.} Though they both meet our basic storage needs, they do so in different ways and require different levels of effort to set up and maintain.

These two services are certainly not the only way to make your research files available. Research oriented services include the SDSC Cloud,\footnote{\url{https://cloud.sdsc.edu/hp/index.php}} the Dataverse Network Project,\footnote{\url{http://thedata.org/}}, figshare\footnote{\url{http://figshare.com/}} and RunMyCode.\footnote{\url{http://www.runmycode.org/}} These services include good built-in citation systems, unlike Dropbox and GitHub. They may be a very good place to store research files once the research is completed or close to completion. Some journals are beginning to require key reproducibility files be uploaded to these sites. However, these sites' ability to store, access, collaborate on, and version control files \emph{during} the main part of the research process is mixed. Services like Dropbox and Github are very capable of being part of the research workflow from the beginning.

\subsection{Dropbox}

The easiest types of cloud storage for your research are services like Dropbox\footnote{\url{http://www.dropbox.com/}} and Google  Drive.\footnote{\url{https://drive.google.com/}} These services not only store your data in the cloud, but also provide some way to share files and even includes basic version control capabilities. I'm going to focus on Dropbox because it currently offers a complete set of features that allow you to store, version, collaborate, and access your data. I will focus on how to use Dropbox on your computer. Some Dropbox functionality may be different on mobile devices.

\subsection{Storage}

When you sign up for Dropbox and install the program\footnote{See \url{https://www.dropbox.com/downloading} for downloading and installation instructions.} it creates a directory on your computer's hard drive. When you place new files and folders in this directory and make changes to them, Dropbox automatically syncs the directory with a similar folder on a cloud-based server. Typically you can sign up to the service and receive a limited amount of storage space for free; usually a few gigabytes.

\subsubsection{Accessing Data}

There are two similar, but importantly different ways to access data stored on Dropbox. All files stored on Dropbox have a URL address through which they can be accessed from a computer connected to the internet. Some of these files can be easily loaded directly into R, while others must me manually (point-and-click) downloaded onto your computer and then loaded into R. Files in the \emph{Public}\index{Dropbox Public folder} folder can be downloaded directly into R. Files not in the \emph{Public} folder have to be downloaded  manually.\footnote{This is not completely true. It could be possible to create a web scraper\footnote{web scraper} that could download data from a file not in your \emph{Public} folder. However, this is kind of a hassle and not practical, especially since the accessing files from the \emph{Public} folder is so easy.}

Either way you find a file's URL address by first right-clicking on the file icon in you Dropbox folder. If the file is stored in the \emph{Public} folder, you go to \texttt{Dropbox} in the menu that pops up, then click \emph{Copy Public Link}. This copies the URL into your clipboard from where you can paste it into your R source code (or wherever). Once you have the URL you can load the file directly into R using the \texttt{read.table} command for data frames (see Chapter 5) or the \texttt{source} command for source code files (see Chapter 8).

To give you a preview of how to download data directly into R from Dropbox, try downloading a data file from my Public folder. The full URL of the data set is: \url{http://dl.dropbox.com/u/12581470/code/Replicability_code/Fin_Trans_Replication_Journal/Data/public.fin.msm.model.csv}. I've used the URL shortening service bitly\footnote{See \url{https://bitly.com/}.}
to make this link fit on the page.

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcomment{# Download data stored in a Dropbox Public folder}
\hlcomment{# and save as an object named Data}
Data <- \hlfunctioncall{read.table}(\hlstring{"http://bit.ly/PhjaPM"}, 
                    sep = \hlstring{","}, header = TRUE)
                    
\hlcomment{# Show variables in Data}
\hlfunctioncall{names}(Data)
\end{alltt}
\begin{verbatim}
## [1] "idn"        "country"    "year"       "reg_4state"
\end{verbatim}
\end{kframe}
\end{knitrout}


If the file is not in your \emph{Public} folder you also go to \texttt{Dropbox} after right-clicking on the file. Then choose \texttt{Get Link}. This will open a webpage in your default web browser from where you can download the file. You can copy and paste the page's URL from your browser's address bar. You can also get these URL links through the online version of your Dropbox. First log into the Dropbox website. If the file is in your \emph{Public} folder, right-click on it and then select \texttt{Copy Public Link}. When you hover your curser over a file or folder not in the \emph{Public} Folder you will see a chain-link icon appear on the far right. Clicking on this icon will get you the link.

Storing files in the \emph{Public} folder clearly makes replication easier because the files can be downloaded and run directly in R.

\subsection{Collaboration}

Though others can easily access your data and files through Dropbox URL links, you cannot save files through the link. You must save files in the Dropbox folder on your computer or upload them through the website. If you would like collaborators to be able to modify the research files you will need to `share' the Dropbox folder with them. You cannot share your \emph{Public} folder, so you will need to keep the files you want collaborators to be able to modify in a non-public folder. Once you create this folder you can share it with your collaborators by right-clicking on the folder and selecting \texttt{Invite to folder} on the Dropbox website or \texttt{Dropbox} \textrightarrow\: \texttt{Share This Folder\ldots} on the locally stored folder. Enter your collaborator's email address when prompted. They will be sent an email that will allow them to accept the share request and, if they don't already have an account, sign up for Dropbox.

\subsubsection{Version control}

Dropbox has a simple version control system. Every time you save a document on Dropbox a new version is created. To view a previous version, navigate to the file on the Dropbox website. Then right-click on the file. In the menu that pops up select \texttt{Previous Versions}. This will take you to a webpage listing previous versions of the file, who created the version, and when it was created. A new version of a file is created every time you save a file and it is synced to the Dropbox cloud service. 

\subsection{GitHub}

Dropbox adequately meets our four basic criteria for reproducible data storage and is easy to set up. GitHub meets the criteria and more, but is less straightforward at first.

GitHub is an interface and cloud hosting service built on top of the Git\index{git} version control system. GitHub was not explicitly designed to host research projects or even data. It was designed to host ``socially coded" computer programs--in what Git calls ``repositories"\index{repository}--by making it easy for a number of collaborators to work together to build computer programs. This seems very far from reproducible research.

Remember that as reproducible researchers we are building projects out of interconnected text files. In important ways this is exactly the same as building a computer program. Computer programs are also basically large collections of interconnected text files. Like computer programers, we need ways to store, version control, access, and collaborate on our text files. Because GitHub is very actively used by people with very similar needs (who are also really good programmers), the interface offers many highly developed and robust features for reproducible researchers.

GitHub's extensive features and heart in the computer programming community means that it takes a longer time than Dropbox to set it up and become familiar with it. So we need good reasons to want to invest the time needed to learn GitHub compared to Dropbox and similar services. Here is a list of GitHub's advantages over Dropbox for reproducible research that will hopefully convince you to get started using it: \\[0.25cm]

\noindent{\bf{Storage and Access}}
\begin{itemize}
    \item Dropbox simply creates folders stored in the cloud which you can share with other people. GitHub makes your projects accessible on a fully featured project website (see Figure \ref{BookRepository}). An example feature is that it automatically renders Markdown files called {\emph{README.md}}\footnote{You can use a variety of other markup languages as well. See \url{https://github.com/github/markup}.} in a GitHub directory on the repository's website. This makes it easy for independent researchers to find the file and read it.   
    \item Public repositories--those viewable by anyone--can be downloaded by anyone in a compressed format.
    \item GitHub can create and and host a website for your research project that you could use to present the results, not just the replication files.
\end{itemize} \\[0.25cm]

       
\noindent{\bf{Collaboration}} \\[0.25cm]

Dropbox allows multiple people to share files and change them. GitHub does this and more:

\begin{itemize}
        \item GitHub keeps meticulous records of who contributed what to a project.
        \item Each GitHub repository has an ``Issues'' area where you can note issues and discuss them with your collaborators. Basically this is an interactive to-do list for your research project. It also stores the issues so you have a full record.
        \item Each repository can also host a wiki\index{wiki} that, for example, could explain in detail how certain aspects of a research project were done.
        \item Anyone can suggest changes to files in a public repository. These changes can be accepted or declined by the project's authors. The changes are recorded by the Git version control system. This could be especially useful if an independent researcher notices an error. 
\end{itemize}\\[0.25cm]

\noindent{\bf{Version Control}}    
\begin{itemize}
\item
  Dropbox's version control system only lets you the see files' names, the times they were created, who created them, and revert back to specific versions. Git tracks every change you make. The GitHub website and GUI programs for Mac and Windows provide nice interfaces for examining specific changes in text files.
\item
  Dropbox creates a new version every time you save a file. This can make it difficult to actually find the version you want as the versions quickly multiply. Git's version control system only creates a new version when you tell it to.
\item
  Dropbox does not merge conflicting versions of a file together. This can be annoying when you are collaborating on project and more than one author is making changes to documents at the same time. GitHub identifies conflicts and lets you reconcile them.
\item
  Git is directly integrated into RStudio Projects\index{RStudio Projects}.\footnote{RStudio also supports the Subversion version
  control system, but I don't cover that here.}
\end{itemize}

\begin{figure}[t]
    \caption{Part of this Book's GitHub Repository Webpage}
    \label{BookRepository}
    \begin{center}
    \includegraphics[scale=0.5]{/git_repositories/Rep-Res-Book/Source/Children/Chapter5/images5/GitHubReadme.png}
    \end{center}
\end{figure}

\subsubsection{Setting up GitHub: Basic}

There are two ways to set up and use GitHub on your computer. You can use the command line version. It's available for Mac and and Linux and Windows through Git Bash\index{Git Bash}, which is automatically installed when you download it. You can also use the Graphical User Interface GitHub program currently available only for Windows and Mac. The GitHub website has excellent step-by-step instructions for how to install both versions. The first thing to do is go to the GitHub website (\url{https://github.com/}) and sign up for an account. Then you should go to one of the following website for instructions on setting up Git: \url{https://help.github.com/articles/set-up-git}.


\todo[inline]{The remainder of this chapter is incomplete.}

\subsubsection{Storage on GitHub}

Files are stored on GitHub in repositories\index{Github repository}. Repositories are kind of like folders, it's probably best to think of them as your projects' parent directories.

To set up a GitHub repository\ldots

\paragraph{Setting up GitHub with RStudio Projects}

Once you have your repository set up on GitHub you can clone it onto your computer and create an RStudio Project\index{RStudio Projects}

\subsubsection{Accessing on GitHub}

\subsubsection{Collaboration with GitHub}

Repositories can have official collaborators. Public repositories can have unlimited collaborators. Anyone with a GitHub account can be a collaborator. 
 

Anyone with a GitHub account can make changes to files in a public repository on the repository's website. Simply click the \texttt{Edit} button above the file and make edits. If the person making the edits is not a repository collaborator, their edit will be sent to the repository's owner for approval.\footnote{This is called a \texttt{pull}\index{git pull} in git terminology}. This is a useful way for independent researchers to catch errors and directly address them.

\paragraph{Branches}

\paragraph{Syncing repository}

\subsubsection{Version Control with GitHub}

GitHub's version control system is much more comprehensive than Dropbox's. However, it also has a steeper learning curve.

\paragraph{Reverting to an old version of a file}

You can use the {\tt{git checkout}} command to revert to a previous version of a document, because you accidentally deleted something important or made other changes you don't like. To `checkout' a particular version of a file type:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
git checkout COMMITREF FILENAME
\end{alltt}
\end{kframe}
\end{knitrout}


\noindent Now the previous version of the file is in your working directory, where you can commit it as usual.

Let's break down the code.  {\tt{FILENAME}} is the name of the file that you want to change\footnote{If it is in a repository's subdirectory you will need to include this in the file name.} and {\tt{COMMITREF}} is the reference that git gave to the commit you want to revert back to. The reference is easy to find and copy in GitHub. On the file's GitHub page click on the {\tt{History}} button. This will show you all of the commits. By clicking on {\tt{Browse Code}} you can see what the file at that commit looks like. Above this button is another with a series of numbers and letters. This is the commit's SHA (Secure Hash Algorithm)\index{SHA}. For our purposes, it is the commit's reference number. Click on the {\tt{Copy SHA}} button to the left of the SHA to copy it. You can then paste it as an argument to your {\tt{git checkout}} command. 

\paragraph{More Practice with Command Line GitHub}

If you want more practice setting up GitHub in the command line, GitHub and the website Code School have an interactive tutorial that you might find interesting. You can find it at: \url{http://try.github.com/levels/1/challenges/4}.
% Chapter Chapter 6 For Reproducible Research in R and RStudio
% Christopher Gandrud
% Created: 16/07/2012 05:45:03 pm CEST
% Updated: 14 October 2012




\chapter{Gathering Data with R}\label{DataGather}

How you gather your data directly impacts how reproducible your research will be. Of course you should try your best to document everything. Reproduction will be easier if your documentation--especially, variable descriptions and source code--makes it so that you and others can understand what you have done. If all of your data gathering steps are embedded in source code, then independent researchers (and you) can more easily regather the data. Regathering data will be easiest if your source code can tie your analysis code all the way back to the raw data--the rawer the better. Of course this may not always be possible. You may need to conduct interviews or compile information from paper based archives, for example. The best you can sometimes do is describe your data gathering process in detail. Nonetheless, R's automated data gathering capabilities for internet-based information are extensive. Learning how to take full advantage of them greatly increases reproducibility and can save you considerable time and effort.

In this chapter you'll learn how to gather quantitative data in a reproducible and, in some cases, fully replicable way. You'll start by learning how to use data gathering make files\index{make file} to organize your whole data gathering process so that it can be completely reproduced. Then you will learn the details of how to actually load data into R from various sources, both locally on your computer and via the internet. In the next chapter (Chapter \ref{DataClean}) you'll learn the details of how to clean up raw data so that it can be merged together into data frames that you can use for statistical analyses.

%%%%%%%%%%%%% Organizing data gathering
\section{Organize your data gathering: make files}

Before getting into the details of using R to gather data, lets's start by creating a plan to organize the process. Organizing your data gathering process from the beginning of a research project improves the possibility of reproducibility and can save you significant effort over the course of the project by making it easier to add and regather data later on. 

A key part of reproducible data gathering with R, like reproducible research in general is segmenting the process into discrete files that can be run by a common make file\index{make file}. Segmentation makes it easier to navigate research text and find errors in the source code. The make file's output is the data set(s) that you'll use in the statistical analyses. There are two types of source code files that the make file runs: data gathering/clean up files and merging files. Data clean up files bring raw (the rawer the better) individual data sources into R and transform them so that can be merged with data from the other sources. Some of the R tools for data clean up and merging will be covered in Chapter \ref{DataClean}. In this chapter we mostly cover the ways to bring raw data into R. Merging files are executed by the make file after it runs the data gathering/clean up files.

It's a good idea to have the source code files use very raw data as input. Your source code should avoid directly changing these raw data files. Instead changes should be output to new objects and data files. Doing this makes it easier to reconstruct the steps you took to create your data set. Also, while cleaning and merging your data you may transform it in an unintended way, for example, accidentally deleting some observations that you had wanted to keep. Having the raw data makes it easy to go back and correct your mistakes. 

In data gathering make files you usually only need one or two commands {\tt{setwd}}\index{setwd} and {\tt{source}}\index{source}. As we talked about in Chapter \ref{DirectoriesChapter}, {\tt{setwd}} simply tells R where to look for and place files. {\tt{source}} tells R to run code in an R source code file.\footnote{We use the {\tt{source}} command is used more in the Chapter \ref{StatsModel}.}  Lets see what a data make file might look like for our example project (see Figure \ref{ExampleTree}). The file paths in this example are for Unix-like systems.

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcomment{################}
\hlcomment{# Example Make file}
\hlcomment{# Christopher Gandrud}
\hlcomment{# Updated 10 October 2012}
\hlcomment{################}

\hlcomment{# Set working directory}
\hlfunctioncall{setwd}(\hlstring{"/ExampleProject/Data/"})

\hlcomment{# Gather and clean up raw data files.}
\hlfunctioncall{source}(\hlstring{"/GatherSource/IndvDataGather/Gather1.R"})

\hlfunctioncall{source}(\hlstring{"/GatherSource/IndvDataGather/Gather2.R"})

\hlfunctioncall{source}(\hlstring{"/GatherSource/IndvDataGather/Gather3.R"})
    
\hlcomment{# Merge cleaned data files into object CleanedData}
\hlfunctioncall{source}(\hlstring{"GatherSource/MergeData.R"})

\hlcomment{# Save cleaned & merged Data as MainData.csv}
\hlfunctioncall{write.csv}(CleandedData, file = \hlstring{"/DataFiles/MainData.csv"})
\end{alltt}
\end{kframe}
\end{knitrout}


This code first sets the working directory. Then the make file runs three source code files to gather data from three different sources. These files gather the data and clean it so that it can be merged together. Next the make file runs a source code file that merges the data frames. Finally, it saves the output data frame {\emph{CleanData}} as a \texttt{.csv} formated file called {\emph{MainData.csv}} using the {\tt{write.csv}}\index{write.csv} command. In our example project, this would be the main file we use for statistical analysis. 

Now that we've covered the big picture, let's learn the different tools you will need to know to gather data from different types of sources.

\section{Importing locally stored data sets}

The most straightforward place to load data from is a local file, e.g. one stored on your computer. Though storing your data locally does not really encourage reproducibility, most research projects will involve loading data this way at some point. The tools you will learn for importing locally stored data files will also be important for most of the other methods further on. Let's briefly look at how to load single and multiple files locally.

\subsection{Importing a single locally stored file}

As we have seen, plain-text file based data stored on your computer can be loaded into R using the \texttt{read.table}\index{read.table} command. If you are using RStudio you can do the same thing with drop down menus. To open a plain-text data file click on \texttt{Workspace} \textrightarrow\: \texttt{Import Dataset\ldots} \textrightarrow\: \texttt{From Text File\ldots}. In the box that pops up, specify the separator, whether or not you want the first line to be treated as variable labels, and other options. This is initially easier than using \texttt{read.table}. But it is less reproducible.

If the data is not stored in plain-text format, but is instead saved by another statistical program such as SPSS, SAS, or Stata, we can import it using commands in the \emph{foreign} package\index{foreign}. For example, imagine we have a data file called \emph{Data1.dta} stored in our working directory. This file was created by the Stata\index{Stata} statistical program. To load the data into an R data frame object called \emph{StataData} simply type:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcomment{# Load library}
\hlfunctioncall{library}(foreign)

\hlcomment{# Load Stata formatted data}
StataData <- \hlfunctioncall{read.dta}(file = \hlstring{"Data1.dta"})
\end{alltt}
\end{kframe}
\end{knitrout}


As you can see, commands in the \emph{foreign} library have similar syntax to \texttt{read.table}. To see the full range of commands and file formats that the \emph{foreign} package supports use the following command:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlfunctioncall{library}(help = \hlstring{"foreign"})
\end{alltt}
\end{kframe}
\end{knitrout}


If you have data stored in a spreadsheet format such as Excel's \texttt{.xlsx}, it may be best to first clean up the data in the spreadsheet program by hand and then save the file in plain-text format. When you clean up the data make sure that the first row has the variable names and that observations are in the following rows. Also, remove any extraneous information--notes, colors, and so on--that will not be part of the data frame.

To aid reproducibility, locally stored data should include careful documentation of where the data came from and how, if at all, it was transformed before it was loaded into R. Ideally the documentation would be written in a text file saved in the same directory as the raw data file. 

\subsection{Looping through multiple files}

\todo[inline]{This subsection needs to be written.}

\section{Importing data sets from the internet}

There are many ways to import data that is stored on the internet directly into R. We have to use different methods depending on where and how the data is stored. 

\subsection{Data from non-secure ({\tt{http}}) URLs}

Importing data into R that is located at a non-secure URL--ones that start with {\tt{http}}--is straightforward provided that:

\begin{itemize}
    \item the data is stored in a simple format, e.g. plain-text,
    \item the file is not embedded in a larger HTML website.
\end{itemize}

We have discussed the first issue in detail. You can determine if the data file is embedded in a website by opening the URL. If you only see the raw plain-text data, you are probably good to go.\footnote{If the data is embedded in a larger website--the way data is usually stored on the cloud version of Dropbox--you may still be able to download it into R. However, this can be difficult and varies depending on the structure of the website. So, I do not cover it in this book.}

To import the data simply include the URL as the file name in your \texttt{read.table} command. We saw earlier how to download a CSV data file from a Dropbox \emph{Public} folder with the shortened URL \texttt{http://bit.ly/PhjaPM}:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
Data <- \hlfunctioncall{read.table}(\hlstring{"http://bit.ly/PhjaPM"}, 
                    sep = \hlstring{","}, header = TRUE)
\end{alltt}
\end{kframe}
\end{knitrout}


\subsection{Data from secure ({\tt{https}}) URLs}

\noindent We have to take a few extra steps to download data from a secure URL. You can tell if the data is stored at a secure web address if it begins with \texttt{https} rather than \texttt{http}. We need the help of the \texttt{getURL}\index{getURL} command in the {\emph{RCurl}} package \cite[]{R-RCurl} and \texttt{textConnection}. The latter command is in base R. The two rules about data being stored in plain text-formats and not being embedded in a large HTML website apply to secure web addresses as well.

Let's try an example. I have data in comma-separated values format stored at a GitHub\index{GitHub} repository. The URL for the ``raw" (plain-text) version of the data is \url{https://raw.github.com/christophergandrud/Disproportionality_Data/master/Disproportionality.csv}.\footnote{To find the URL for the raw version of a file on the GitHub website simply click the \texttt{Raw} button on the right just above the file preview.} Imagine that we put the address as a character string into an object called {\emph{UrlAddress} (not shown).\footnote{See page \pageref{Objects} for how to put a character string into an object. I do not show how this was done in the book, due to space constraints.}
To download it into R we could use this code:




\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcomment{# Load package}
\hlfunctioncall{library}(RCurl)

\hlcomment{# Pull data from the internet}
Data <- \hlfunctioncall{getURL}(UrlAddress)

\hlcomment{# Convert Data into a data frame}
Data <- \hlfunctioncall{read.table}(\hlfunctioncall{textConnection}(Data), 
                    sep = \hlstring{","}, header = TRUE)
                    
\hlcomment{# Show variables in data}
\hlfunctioncall{names}(Data)
\end{alltt}
\begin{verbatim}
## [1] "country"            "year"              
## [3] "disproportionality"
\end{verbatim}
\end{kframe}
\end{knitrout}


\subsection{Compressed data stored online}

Sometimes data files are large, making them difficult to store and download without compressing\index{file compression} them. There are a number of compression methods such as Zip and tar.\footnote{Tar archives are sometimes referred to as `tar balls'.} Zip files have the extension {\tt{.zip}} and tar files use extensions such as {\tt{.tar}} and {\tt{.gz}}. In most cases\footnote{Some formats that require the {\emph{foreign}} package to open are more difficult. This is because functions such as {\tt{read.dta}} for opening Stata {\tt{.dta}} files only accept file names or URLs as arguments, not connections, which you create for unzipped files.} you can download, decompress, and create data frame objects from these files directly in R. 

To do this you need to:\footnote{The description of this process is based on a Stack Overflow comment by Dirk Eddelbuettel (see {\url{http://stackoverflow.com/questions/3053833/using-r-to-download-zipped-data-file-extract-and-import-data?answertab=votes\#tab-top}}, accessed 16 July 2012.}

\begin{itemize}
    \item create a temporary file with {\tt{tempfile}} to store the zipped file, which you will later remove with the {\tt{unlink command}} at the end,
    \item download the file with {\tt{download.file}},
    \item decompress the file with one of the {\tt{connections}} commands in base R,\footnote{To find a full list of commands type {\tt{?connections}} into the R console.}
    \item read the file with {\tt{read.table}}. 
\end{itemize}

\noindent The reason that we have to go through so many extra steps is that compressed files are more than just a single file, but can contain a number of files as well as metadata.

Let's download a compressed file called {\emph{uds\_summary.csv}} from \cite{Pemstein2010}. It is in a compressed file called {\emph{uds\_summary.csv.gz}}. The file's URL address is {\url{http://www.unified-democracy-scores.org/files/uds_summary.csv.gz}}, that I shortened\footnote{Again, I used bitly (\url{bitly.com}) to shorten the URL.} to \url{http://bit.ly/S0vxk2} because of space constraints.

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcomment{# For simplicity, store the URL in an object called \hlstring{'url'}.}
url <- \hlstring{"http://bit.ly/S0vxk2"}

\hlcomment{# Create a temporary file called \hlstring{'temp'} to put the zip file into.}
temp <- \hlfunctioncall{tempfile}()

\hlcomment{# Download the compressed file into the temporary file.}
\hlfunctioncall{download.file}(url, temp)

\hlcomment{# Decompress the file and convert it into a dataframe}
\hlcomment{# class object called \hlstring{'data'}.}
Data <- \hlfunctioncall{read.csv}(\hlfunctioncall{gzfile}(temp, \hlstring{"uds_summary.csv"}))

\hlcomment{# Delete the temporary file.}
\hlfunctioncall{unlink}(temp)

\hlcomment{# Show variables in data}
\hlfunctioncall{names}(Data)
\end{alltt}
\begin{verbatim}
## [1] "country" "year"    "cowcode" "mean"    "sd"     
## [6] "median"  "pct025"  "pct975"
\end{verbatim}
\end{kframe}
\end{knitrout}


\subsection{Data APIs \& feeds}

\todo[inline]{The remainder of this chapter is incomplete.}

There are a growing number of packages that can gather data directly from a variety of internet sources and import them into R. Needless to say, this is great for reproducible research. It not only makes the data gathering process easier as you don't have to download many of Excel files and fiddle around with them before even getting the data into R, but it also makes replicating the data gathering process much more straightforward. Some examples of these packages include: 

\begin{itemize}
    \item \todo[inline]{Need to Complete list.}
    \item The \emph{openair} package, which beyond providing a number of tools for analysing air quality data also has the ability to directly gather data directly from sources such as Kings College London's London Air (\url{http://www.londonair.org.uk/}) database with the \texttt{importKCL} command.
\end{itemize}

\section{Basic web scraping}

\subsection{Gathering and parsing text from the web}

\subsection{Scraping tables}



% Chapter Chapter 7 For Reproducible Research in R and RStudio
% Christopher Gandrud
% Created: 16/07/2012 05:45:03 pm CEST
% Updated: 14 October 2012




\chapter{Preparing Data for Analysis}\label{DataClean}

\todo[inline]{This chapter is incomplete.}

Once we have gathered the raw data that we want to include in our statistical analyses we generally need to clean it and merge it into a single data file. This chapter covers some of the basics of how to clean data files and merge them together into one data frame using R. 

If you are very familiar with data transformations in R you may want to skip onto the next chapter. 

\section{Cleaning data for merging}

\subsection{Renaming variables}

\subsection{Changing variables types}

\subsection{Creating ID Variables}

\subsection{Sorting \& ordering data}

\section{Merging data sets}

\subsection{Binding}

\subsection{The merge command}


% Part 3, include child documents
\part{Analysis and Results}

% Chapter Chapter 8 For Reproducible Research in R and RStudio
% Christopher Gandrud
% Created: 16/07/2012 05:45:03 pm CEST
% Updated: 14 October 2012




\chapter{Statistical Modelling and knitr}\label{StatsModel}

When you have your data cleaned and organized you will begin to examine it with statistical analysis. To make your analysis really reproducible you should dynamically connect the source code of your analysis to your data make file and presentation documents. Connecting to the data make file could involve actually including the code to run your make file in the analysis source code with the \texttt{source} command or if this is computationally intensive you may include this code in the comments so that independent researchers can easily rerun it. Clearly you will directly link to the output of the data gathering make file when you load the data it produced for your statistical analysis. When you dynamically connect your source code file to your markup document you will be able to run your analysis and present the results whenever you compile the presentation documents. Doing this makes it very clear how you found the results that you are advertising. It also automatically keeps the presentation of your results--including tables and figures--up-to-date with any changes you make to your data and analysis.

You can dynamically tie your statistical analyses and presentation documents together with {\emph{knitr}}. In Chapter \ref{GettingStartedRKnitr} you learned basic {\emph{knitr}} syntax. In this chapter you will begin to learn {\emph{knitr}} syntax in much more detail, particularly code chunk options for including dynamic code in your presentation documents. This includes code that is run in the background, i.e. not shown in the presentation document as well as displaying the code and output in your presentation document both as separate blocks and inline with the text. You will also learn how to dynamically include code from languages other than R. We will finally examine how to use {\emph{knitr}} when you segment your analysis into a number of modular source code files. 

The goal of this and the next two chapters--which cover dynamically presenting results in tables and figures--is to show you how to tie your analyses into your presentation documents so closely that every time the documents are compiled they actually reproduce your analysis and present the results.

Please see the next part of this book, Part IV, for details on how to create the LaTeX and Markdown documents that can include {\emph{knitr}} code chunks.

\section{Incorporating analyses into the markup}

For a relatively short piece of code that you don't need to run in multiple presentation documents it may be simplest to type the code directly into chunks written in your markup document. In this section you will learn how set {\emph{knitr}} options to handle these code chunks.

\subsection{Full code chunks}

By default {\emph{knitr}} code chunks are run by R, the code and any text output (including warnings and error messages) are inserted into the text of your presentation documents in blocks. The blocks are positioned in the final presentation document text exactly where they are written in the markup version. Figures are inserted as well. Let's look at the main options for determining how R code is handled by {\emph{knitr}}.

\paragraph{{\tt{eval}}}\index{eval}

Set the \texttt{eval} option to \texttt{FALSE} if you would like to include code chunks without actually running them.

\paragraph{{\tt{echo}}}\index{echo}

The opposite of \texttt{eval=FALSE} is to have the code chunk evaluated but have the code not included in the presentation document. You can do this by setting \texttt{echo=TRUE}. You will use this option extensively in chapters \ref{TablesChapter} and \ref{FiguresChapter} when you learn how to run R source code to produce tables and figures that are included presentation documents' text.

\paragraph{{\tt{warning}}, {\tt{message}}, {\tt{error}}}\index{warning}\index{error}\index{message}

If you don't want to include in the text of your presentation documents the warnings, messages, and error messages that R outputs when it runs a code chunk just set the \texttt{warning}, \texttt{message}, and \texttt{error} options to \texttt{FALSE}.

\paragraph{{\tt{cache}}}\index{cache}

If you want to store a code chunk's output for use later, rather than running the code chunk every time you compile your presentation document, set the option \texttt{cache=TRUE}. When you do this the code chunk is run only if the code changes. It is very handy if you have a code chunk that is computationally intensive to run. 

Unfortunately, the \texttt{cache} option has some limitations. For example, other code chunks can't access objects that have been cached.

\subsection{Showing code \& results inline}

Sometimes you may want to have some R code or text output show up inline with the rest of your presentation document's text. For example, you may want to include a small chunk of stylized code in your text when you discuss how you did an analysis. Or you may want to dynamically report the mean of some variable in your text so that the text will change if you change the data. The {\emph{knitr}} syntax for including inline code is different for the LaTeX and Markdown languages. We'll cover both in turn.

\subsubsection{LaTeX}

\paragraph{Inline static code}

If you want to include a code snippet inline with your text you can simply use the LaTeX command  \texttt{\textbackslash{}texttt}\index{tt}. This sets your text to `typewriter' font, the standard font for inline code in LaTeX (I use it in this book, as you have probably noticed). It is equivalent to the \texttt{eval=FALSE} option for full code chunks. 

\paragraph{Inline dynamic code}

If you want to dynamically show the results of some R code in your LaTeX produced text you can use the  \texttt{\textbackslash Sexpr} command\index{Sexpr}. This is a pseudo LaTeX command; it looks like LaTeX, but is actually {\emph{knitr}}.\footnote{The command directly descends from Sweave.} Its structure is more like a LaTeX command's structure than \texttt{knitr}'s in that you enclose your R code in curly brackets (\texttt{\{\}}) rather than the usual \texttt{\textless\textless\textgreater\textgreater= . . . @} syntax for block code chunks.

For example, imagine that you wanted to include the mean of a vector of river lengths--591--in the text of your document. The {\emph{rivers}} numeric vector, loaded by default in R, has the length of 141 major rivers recorded in miles. You can simply use the {\tt{mean}} command to find the mean and the {\tt{round}} command to round it to the nearest whole number:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlfunctioncall{round}(\hlfunctioncall{mean}(rivers), digits = 0)
\end{alltt}
\begin{verbatim}
## [1] 591
\end{verbatim}
\end{kframe}
\end{knitrout}


\noindent To have just the output show up inline with the text of your document you would type something like:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
The mean length of 141 major rivers in North America
is \textbackslash{}Sexpr\{\hlfunctioncall{round}(\hlfunctioncall{mean}(rivers), digits = 0)\} miles. 
\end{alltt}
\end{kframe}
\end{knitrout}


\noindent This produces the sentence:

\begin{quote}
    The mean length of 141 major rivers in North America is 591 miles. 
\end{quote}

\subsubsection{Markdown}

\paragraph{Inline static code}

To include static code inline in an R Markdown (and regular Markdown) document, enclose the code in single backticks (\` \`). For example:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
This is example R code: `MeanRiver <- \hlfunctioncall{mean}(rivers)`.
\end{alltt}
\end{kframe}
\end{knitrout}


\noindent produces:\footnote{The exact look of the text depends on the CSS\index{CSS} style file you are using.}

\includegraphics[scale = 0.6]{/git_repositories/Rep-Res-Book/Source/Children/Chapter8/images8/MeanRiverMarkdown.png}

\paragraph{Inline dynamic code}

Including dynamic code in the body of your R Markdown text is similar to including static code. The only difference is that you put the letter \texttt{r} after the first single backtick. For example:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
`r \hlfunctioncall{mean}(rivers)`
\end{alltt}
\end{kframe}
\end{knitrout}


\noindent will include the mean value of the {\emph{rivers}} vector in the text of your Markdown document.

\subsection{Dynamically including non-R code}

You are not limited to dynamically including just R code in your presentation documents. {\emph{knitr}} can run code from a variety of other languages including: Python\index{Python}, Ruby, Bash, Haskell, and Awk. All you have to do to dynamically include code from one of these languages is set the \texttt{engine}\index{engine} code chunk option. For example, to dynamically include a simple line of Ruby code in an R Markdown document simply type:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{verbatim}
```{r engine='ruby'}
print "Reproducible Research"
 

Reproducible Research
```
\end{verbatim}
\end{kframe}
\end{knitrout}

The programming language values \texttt{engine} can take are listed in Table \ref{EngineOptions}. Please note that currently the range of functions {\emph{knitr}} supports for these languages is less extensive than what it supports for R. For example, there is no colored syntax highlighting.

\section{Dynamically including modular analysis files}

There are a number of reasons that you might want to have your R source code located in separate files from your markup documents even if you compile them together with {\emph{knitr}}.

\begin{wraptable}{rt}{0.4\textwidth}
    \caption{Knitr \texttt{engine} Values}
    \label{EngineOptions}
    \begin{tabular}{l p{2.25cm}}
    \hline\vspace{0.15cm}
    Value & Programming Language \\
    \hline\hline
    \texttt{awk} & Awk\index{Awk} \\
    \texttt{bash} & Bash\index{Bash} \\
    \texttt{gawk} & Gawk\index{Gawk} \\
    \texttt{haskell} & Haskell\index{Haskell} \\
    \texttt{highlight} & Highlight\index{Highlight, knitr engine option} \\ 
    \texttt{python} & Python\index{Python} \\
    \texttt{R} & R (default) \\[0.25cm]
    \texttt{ruby} & Ruby\index{Ruby} \\
    \texttt{sh} & Bash \\
    \hline
    \end{tabular}
\end{wraptable}

First, it can be unwieldy to edit both your markup and long R source code chunks in the same document, even with RStudio's handy {\emph{knitr}} code folding and chunk management options. There are just too many things going on in one document. 

Second, you may want to use the same code in multiple documents--an article and presentation for example. It is nice to not have to copy and paste the same code into multiple places. Instead it is easier to have multiple documents link to the same source code. When you make changes to this source code files, the changes will automatically be made across all of your presentation documents. You don't need to make the same changes multiple times.

Third, other researchers trying to replicate your work might only be interested in specific parts of your analysis. If you have the analysis broken into separate and clearly labeled modular files that are explicitly tied together in the markup file with {\emph{knitr}} it is easy for them to find the specific bits of code that they are interested in.

\subsection{Source from a local file}

Usually in the early stages of research you may want to run code stored in analysis files located on your computer. Doing this is simple. The {\emph{knitr}} syntax is the same as for block code chunks. The only change is that instead of writing all of your code in the chunk you save it to its own file and use the \texttt{source} command to access it. For example, in an R Markdown file we could run the R code in a file called {\emph{MainAnalysis.R}} from our {\exmph{ExampleProject}} like this:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
```\{r, echo=FALSE\}
\hlcomment{# Run main analysis}
\hlfunctioncall{source}(\hlstring{"/ExampleProject/Analysis/MainAnalysis.R"}\}
```
\end{alltt}
\end{kframe}
\end{knitrout}


Notice that we set the \texttt{echo=FALSE} option. This will run the analysis and produce objects created by the analysis code that can be used by other code chunks, but the results are not show in the presentation document's text. Errors, messages, and warnings will be shown, if we do not tell {\emph{knitr}} to hide them.

\subsection{Source from a non-secure URL (\texttt{http})}

Sourcing from your computer is fine if you are working alone and do not want others to access your code. Once you start collaborating and generally wanting people to be able to reproduce your analyses, you need to
use another storage method.%\footnote{You can make the replication code accessible for download and either instruct others to change the working directory to the replication file or have them change the directory information as necessary. However, this usually just adds an extra complicating step that makes replication harder. It is also a pain if you are collaborating and each author has to constantly change the directories.}

The simplest solution to these issues is to host the replication code in your Dropbox public folder. You can find the file's public URL the same that you did in Chapter \ref{Storing}. Now use the \texttt{source} command the same way as before with the URL as the argument.

\subsection{Source from a secure URL (\texttt{https})}

If you are using GitHub\index{GitHub} or another service that uses secure URLs to host your analysis source code files you need to use the \texttt{source\_url} command in the {\emph{devtools}} package \cite[]{R-devtools}. For GitHub based source code we find the file's URL the same way we did in Chapter \ref{Storing}. Remember to use the URL for the {\emph{raw}} version of the file. I have a short script hosted on GitHub for creating a scatterplot from data in R's {\emph{cars}} data set. The script's shortened URL is \url{http://bit.ly/Ny1n6b}.\footnote{The original URL is at \url{https://raw.github.com/christophergandrud/christophergandrud.github.com/master/SourceCode/CarsScatterExample.R}. This is very long, so I shortened it using bitly (see \url{http://bitly.com}). You may notice that the shortened URL is not secure. However, it does link to original secure {\tt{https}} URL.} To run this code and create the scatterplot using {\tt{source\_url}} you simply type:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcomment{# Load library}
\hlfunctioncall{library}(devtools)

\hlcomment{# Run the source code to create the scatter plot}
\hlfunctioncall{source_url}(\hlstring{"http://bit.ly/Ny1n6b"})
\end{alltt}
\end{kframe}

{\centering \includegraphics[width=\maxwidth]{figure/Ch8SourceURLExample} 

}


\end{knitrout}


You can also use the {\emph{devtools}} command \texttt{source\_gitst}\index{source\_gist} in a similar way to source GitHub Gists\index{Gist, GitHub}. Gists are a handy way to share code over the internet. For mor details see: \url{https://gist.github.com/}.

% Chapter Chapter 9 For Reproducible Research in R and RStudio
% Christopher Gandrud
% Created: 16/07/2012 05:45:03 pm CEST
% Updated: 14 October 2012




\chapter{Showing Results with Tables}\label{TablesChapter}

Graphs and other visual methods, discussed in the next chapter, can often be a more effective way to present results than tables.\footnote{This is especially true of the small-print, high-density coefficient estimate tables that are sometimes descriptively called `train schedule' tables.} Nonetheless, tables of parameter estimates, descriptive statistics, and so on can sometimes be an important part of presenting research findings. Learning how to dynamically connect your analysis results with tables in presentation documents aids reproducibility and can ultimately save you a lot of time.

Manually typing results into tables by hand is tedious, not very reproducible, and can introduce errors. It's especially tedious to retype tables to reflect changes you made to your data and models. Fortunately, you don't actually need to create tables by hand. There are many ways to have R do the work for you. 

The goal of this chapter is to learn how to dynamically create tables for you presentation documents written in LaTeX and Markdown. There are a number of ways to turn R objects into tables written in LaTeX or Markdown/HTML markup. In this chapter we mostly focus on the \texttt{xtable} \cite[]{R-xtable} and \texttt{apsrtable} packages \cite[]{R-apsrtable}. \texttt{xtable} can create tables for both of LaTeX and Markdown/HTML. \texttt{apsrtable} only
produces output for LaTeX. \texttt{knitr} allows us to incorporate these tables dynamically into our documents.

\textbf{Warning:} Automating table creation removes the possibility of adding errors to your analyses by incorrectly copying output, which is a big potential problem in hand-created tables. However, it is not error free. You could easily create inaccurate tables through coding errors. So, as always, it is important to `eyeball' the output. Does it make sense? If you select a couple values in the R output do the match what is in the presentation document's table? If not, you need to go back to the code and see where things have gone wrong. With that caveat, let's start making tables.

\section{Table Basics}

Before getting into the details of how to create tables from R objects we need to first learn how generic tables are created in LaTeX and Markdown/HTML.

\subsection{Tables in LaTeX}

\todo[inline]{Much of the rest of the chapter is incomplete.}

\subsection{Tables in Markdown/HTML}

\section{Creating tables from R objects}

\subsection{\texttt{xtable} \& \texttt{apsrtable} basics with supported
class objects}

\subsubsection{\texttt{xtable} for LaTeX}

\subsubsection{\texttt{xtable} for Markdown}

We can use {\emph{xtable}} and the \texttt{print} command to also create tables for Markdown and HTML documents. Instead of setting the \texttt{type} argument to \texttt{`latex`} we simply put it to \texttt{'html'}.


\subsection{\texttt{xtable} with non-supported class objects}

{\tt{xtable}} is very convenient for making tables from objects in supported classes.\footnote{To see a full list of classes that {\tt{xtable}} supports type \texttt{methods(xtable)} into the R console.} With supported class objects {\tt{xtable}} knows where to look for the vectors containing the things--coefficient names, standard errors, and so on--that it needs to create the table. With unsupported classes, however, it doesn't know where to look for these things. You need to help it find them. 

{\tt{xtable}} can handle matrix and data frame class objects. The rows of these objects become the rows of the table and the columns become the table columns. So, to create tables with non-supported class objects you need to

\begin{enumerate}
    \item find and extract the information from the unsupported class object that you want in the table, 
    \item convert this information into a matrix or data frame where the rows and columns of the object correspond to the rows and columns of the table that you want to create,
    \item use {\tt{xtable}} with this object to create the table.
\end{enumerate}

Imagine that you want to create a results table showing the covariate names, coefficient means, and quantiles for marginal posterior distributions from a Bayesian normal linear regression using the {\tt{zelig}} command \cite[]{Goodrich2007,R-Zelig} and data from the {\emph{swiss}} data frame that comes with R. First run the model:

\todo[inline]{Note, I am having trouble with this code using Zelig version 4 and am currently working with the packaged developers to sort the issue out. The code does work with Zelig version 3.5.5.}

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcomment{# Load required library}
\hlfunctioncall{library}(Zelig)

NBModel <- \hlfunctioncall{zelig}(Examination ~ Education, model = \hlstring{"normal.bayes"}, 
                    data = swiss, cite = FALSE)

\hlcomment{# Find NBModel's class}
\hlfunctioncall{class}(NBModel)
\end{alltt}
\begin{verbatim}
## [1] "MCMCZelig"
\end{verbatim}
\end{kframe}
\end{knitrout}


Using the {\tt{class}} command we found that the model output object is a {\tt{MCMCZelig}} class object. This class is not supported by {\tt{xtable}}. If you try to create a summary table called {\emph{NBTable}} of the results you will get the following error:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcomment{# Load required library}
\hlfunctioncall{library}(xtable)

\hlcomment{# Attempt to create a table with NBModel}
NBTable <- \hlfunctioncall{xtable}(NBModel)
\end{alltt}


{\ttfamily\noindent\bfseries\textcolor{errorcolor}{\#\# Error: no applicable method for 'xtable' applied to an object of class "MCMCZelig"}}\end{kframe}
\end{knitrout}


\noindent With unsupported class objects you have to create the summary yourself and extract the elements that you want from it manually. A good knowledge of vectors, matrices, and component selection is very handy for this (see Chapter \ref{GettingStartedRKnitr}). 

First, create a summary of your output object {\emph{NBModel}}:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
NBModelSum <- \hlfunctioncall{summary}(NBModel)
\end{alltt}
\end{kframe}
\end{knitrout}


\noindent You created a new object of the class {\tt{summary.MCMCZelig}}. You're still not there yet as this object contains not just the covariate names and so on but also information you don't want to include in your results table, like the formula that you used. The second step is to extract a matrix from inside {\emph{NBModelSum}} called {\emph{summary}} with the component selector ({\tt{\$}}). Remember that to see the components of an object you can use the \texttt{names} command. The {\emph{summary}} matrix is where the things you want in your table are located. I find it easier to work with data frames, so let's also convert the matrix into a data frame.

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
NBSumDataFrame <- \hlfunctioncall{data.frame}(NBModelSum$summary)
\end{alltt}
\end{kframe}
\end{knitrout}

%%
\noindent Here is what your model results data frame looks like:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{verbatim}
##                Mean      SD   X2.5.    X50.  X97.5.
## (Intercept) 10.1397 1.31673  7.5579 10.1566 12.7058
## Education    0.5786 0.09118  0.3963  0.5781  0.7609
## sigma2      34.9703 7.81260 22.9567 33.8782 53.2172
\end{verbatim}
\end{kframe}
\end{knitrout}


\noindent Now you have a data frame object that {\tt{xtable}} can handle. After a little cleaning up (see the chapter's source code for more details) you can use {\emph{NBSumdata frame}} with {\tt{xtable}} as before to create the following table:
\vspace{0.5cm}


% latex table generated in R 2.15.1 by xtable 1.7-0 package
% Mon Oct 29 09:30:50 2012
\begin{table}[ht]
\begin{center}
\begin{tabular}{rrrrr}
  \hline
 & Mean & 2.5\% & 50\% & 97.5\% \\ 
  \hline
(Intercept) & 10.14 & 7.56 & 10.16 & 12.71 \\ 
  Education & 0.58 & 0.40 & 0.58 & 0.76 \\ 
  sigma2 & 34.97 & 22.96 & 33.88 & 53.22 \\ 
   \hline
\end{tabular}
\caption{Coefficient Estimates Predicting Examination Scores in Swiss Cantons (1888) Found Using Bayesian Normal Linear Regression}
\end{center}
\end{table}




It may take some hunting to find what you want, but a similar process can be used to create tables from objects of virtually any class.\footnote{This process can also be used to create graphics.} Hunting for what you want is generally easier if you look inside of it by clicking on the object in RStudio's {\bf{Workspace}} pane.

\subsection{Basic \texttt{knitr} syntax for tables}

So far we have only looked at how to create LaTeX and HTML tables from R objects. How can we knit these tables into our presentation documents? The most important \texttt{knitr} chunk option for showing tables is \texttt{results}\index{results, knitr option}. The \texttt{results} option can have one of three values:

\begin{itemize}
\item
  \texttt{'markup'},
\item
  \texttt{'asis'},
\item
  \texttt{'hide'}.
\end{itemize}

\noindent The value \texttt{hide} clearly hides the results of you code chunk from your presentation document. To include tables created from R objects in your LaTeX or Markdown output you should set \texttt{results='asis'} or \texttt{results='markup'}. \texttt{asis} simply the writes the raw output in the presentation document where it is then compiled with the rest of the markup. \texttt{markup} uses an output hook\index{hook} to mark up the results in a predfined way.  



% Chapter Chapter 10 For Reproducible Research in R and RStudio
% Christopher Gandrud
% Created: 16/07/2012 05:45:03 pm CEST
% Updated: 12 October 2012




\chapter{Showing Results with Figures}\label{FiguresChapter}

\todo[inline]{This chapter is incomplete.}

\section{Including graphics}

\section{Basic knitr figure options}

\section{Creating figures with plot and ggplot2}

\section{Animations}

\section{Motion charts and basic maps with GoogleVis}


% Part 4, include child documents
\part{Presentation Documents}

% Chapter Chapter 11 For Reproducible Research in R and RStudio
% Christopher Gandrud
% Created: 16/07/2012 05:45:03 pm CEST
% Updated: 14 October 2012




\chapter{Presenting with LaTeX}\label{LatexChapter}

This chapter gives you a quick introduction to basic LaTeX document structures and commands. In the next chapter (Chapter \ref{LargeDocs}) we will build on these skills by learning how to use {\emph{knitr}} to create more complex multi-part LaTeX documents. 

\todo[inline]{Much of this chapter is incomplete.}

\section{The Basics}

\subsection{Editors}

As I mentioned earlier, RStudio is a fully functional LaTeX editor as well as an integrated development environment for R. If you want to create a new LaTeX document you can click {\tt{File}} in the menu bar then {\tt{New}} \rightarrow {\tt{R\; Sweave}}. 

Remember from Chapter \ref{GettingStartedRKnitr} that R Sweave\index{R Sweave} files are basically LaTeX files that can include {\emph{knitr}} code chunks. You can compile R Sweave files like regular LaTeX files in RStudio even if they do not have code chunks. If you use another program to compile them you might need to change the file extension from {\tt{.Rnw}} to {\tt{.tex}}.

\subsection{Basic syntax}

All commands in LaTeX start with the backslash (\texttt{\textbackslash{}}) escape character\index{escape character}. For example, to create a section heading you use the \texttt{section} command. The arguments for LaTeX commands are written inside of curly braces (\texttt{\{\}}) like this:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\textbackslash{}section\{My Section Name\}
\end{alltt}
\end{kframe}
\end{knitrout}


\subsection{The header \& the body}

All LaTeX documents require a header\index{LaTeX header}. The header goes before the body of the document and specifies what type of presentation document you are creating--an article, a book, a slideshow, and so on. LaTeX refers to these as classes\index{LaTeX class}. You can also specify what style it should be formatted in and load any extra packages you may want to use to help you format your document.\footnote{The command to load a package in LaTeX is \texttt{\textbackslash{}usepackage}. For example, if you include \texttt{\textbackslash{}usepackage\{url\}} in the header of your document you will be able to specify URL links in the body with the command \texttt{\textbackslash{}url\{SOMEURL\}}.}

The header is followed by the body of your document. You tell LaTeX where the body\index{LaTeX begin document} of your document starts by typing \texttt{\textbackslash{}begin\{document\}}. The very last line of you document is usually \texttt{\textbackslash{}end\{document\}}, indicating that your document has ended. When you open a new R Sweave file in RStudio it creates an article class document with a very simple header and body like this:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\textbackslash{}documentclass\{article\}

\textbackslash{}begin\{document\}


\textbackslash{}end\{document\}
\end{alltt}
\end{kframe}
\end{knitrout}


\subsection{Headings}

\subsection{Footnotes \& Bibliographies}

\subsubsection{Footnotes}

Plain, non-bibliographic footnotes are easy to create in LaTeX. Simply place \texttt{\textbackslash{}footnote\{} where you would like the footnote number to appear in the text. Then type in the footnote's text. Of course remember to close the footnote with a \texttt{\}}. LaTeX does the rest, including formatting and numbering.

\subsubsection{Bibliographies}

\paragraph{Citing R Packages with BibTeX}

Researchers are pretty good about consistently citing others' articles and data. However, citations of R packages used in analyses is very inconsistent. This is unfortunate not only because correct attribution is not being given to those who worked to create the package, but also because it makes reproducibility harder. It obscures important steps that were taken in the research process, primarily which package versions were used. Fortunately, there are R tools for quickly and dynamically generating citations, including the versions of the packages you are using. It can also add them directly to an existing bibliography file.

You can automatically create citations for R packages using the \texttt{citation} command inside of a code chunk. For example if you want the citation information for the \texttt{xtable} package you would simply type:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlfunctioncall{citation}(\hlstring{"xtable"})
\end{alltt}
\begin{verbatim}
## 
## To cite package 'xtable' in publications use:
## 
##   David B. Dahl (2012). xtable: Export tables to
##   LaTeX or HTML. R package version 1.7-0.
##   http://CRAN.R-project.org/package=xtable
## 
## A BibTeX entry for LaTeX users is
## 
##   @Manual{,
##     title = {xtable: Export tables to LaTeX or HTML},
##     author = {David B. Dahl},
##     year = {2012},
##     note = {R package version 1.7-0},
##     url = {http://CRAN.R-project.org/package=xtable},
##   }
## 
## ATTENTION: This citation information has been
## auto-generated from the package DESCRIPTION file and
## may need manual editing, see 'help("citation")' .
\end{verbatim}
\end{kframe}
\end{knitrout}


\noindent This gives you both the plain citation as well as the BibTeX version for use in LaTeX and MultiMarkdown\index{MultiMarkdown} documents. If you only want the BibTeX version of the citation you can use the \texttt{toBibtex} command in the \emph{utils} package.

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlfunctioncall{toBibtex}(\hlfunctioncall{citation}(\hlstring{"xtable"}))
\end{alltt}
\begin{verbatim}
## @Manual{,
##   title = {xtable: Export tables to LaTeX or HTML},
##   author = {David B. Dahl},
##   year = {2012},
##   note = {R package version 1.7-0},
##   url = {http://CRAN.R-project.org/package=xtable},
## }
\end{verbatim}
\end{kframe}
\end{knitrout}


\noindent You can append the citation to your existing BibTeX file using the \texttt{sink} command in \emph{base} R. This command diverts output and/or the messages to a file. For example, imagine that your existing BibTeX file is called \texttt{biblio.bib}. To add the \emph{xtable} package citation:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcomment{# Divert output to biblio.bib}
\hlfunctioncall{sink}(file = \hlstring{"biblio.bib"}, 
     append = TRUE, type = \hlfunctioncall{c}(\hlstring{"output"})
     )      
\hlcomment{# Extract BibTeX citation     }
\hlfunctioncall{toBibtex}(\hlfunctioncall{citation}(\hlstring{"xtable"})) 
\hlfunctioncall{sink}()
\end{alltt}
\end{kframe}
\end{knitrout}


\noindent This places the citation at the end of your \texttt{biblio.bib} file. It is very important to include the argument \texttt{append = TRUE}. If you don't you will erase the existing file and replace it with only the new citation. The argument \texttt{type = c("output")} tells R to include only the output, not the messages.

A more concise way to add citations to a bibliography is with \texttt{write.bibtex} command in the \emph{knitcitations} package \cite[]{R-knitcitations}. To add the \emph{xtable} citation to our \texttt{biblio.bib} file we only need to enter:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcomment{# Load package}
\hlfunctioncall{library}(knitcitations)
 
\hlcomment{# Write xtable citation and to biblio.bib}
\hlfunctioncall{write.bibtex}(entry = \hlfunctioncall{c}(\hlstring{"xtable"}), 
              file = \hlstring{"bibliography.bib"}, append = TRUE)
\end{alltt}
\end{kframe}
\end{knitrout}


\noindent Note, you will likely only want to append the citations once. Otherwise your bibliography document will grow with redundant information every time you run this command.

The {\emph{knitr}} package can also create BibTeX bibliographies for R packages using the \texttt{write\_bib} command. To use this command you list the packages whose citation details you want to include in a specified file. The command currently does not have the ability to append the citations to an existing file, but instead writes them to a new file.

\section{Presentations with Beamer}

You can make slideshow presentations with LaTeX. 

\subsection{knitr LaTeX slideshows}
{\emph{Knitr}} largely works the same way in in LaTeX slideshows as it does in article or book class documents. There are a few differences to look out for. 

\paragraph{Slide frames}

A quick way to create each Beamer slide is to use the \texttt{frame} command:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\textbackslash{}frame\{
\}
\end{alltt}
\end{kframe}
\end{knitrout}


\noindent If you want to include highlighted {\emph{knitr}} code chunks on your slides you should add the \texttt{fragile} option to the \texttt{frame} command.\footnote{For a detailed discussion of why you need to use the \texttt{fragile} option with the verbatim environment that {\emph{knitr}} uses to display highlighted text in LaTeX documents see this blog post by Pieter Belmans: \url{http://pbelmans.wordpress.com/2011/02/20/why-latex-beamer-needs-fragile-when-using-verbatim/}.} Here is an example:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\textbackslash{}begin\{frame\}[fragile]
    An example fragile frame.
\textbackslash{}end\{frame\}
\end{alltt}
\end{kframe}
\end{knitrout}


\paragraph{Results}

By default {\emph{knitr}} hides code chunk results. If you want to show the results in your slideshow simply set the {\tt{results}} option to {\tt{'asis'}}.
% Chapter Chapter 12 For Reproducible Research in R and RStudio
% Christopher Gandrud
% Created: 16/07/2012 05:45:03 pm CEST
% Updated: 14 October 2012




\chapter{Large LaTeX Documents: Theses, Books, \& Batch Reports}\label{LargeDocs}

\todo[inline]{This chapter is largely incomplete}

In the previous chapter you learned the basics of how to create LaTeX documents to present your research findings. So far you have only learned how to create short documents, like articles. For longer and more complex documents, like books, you can take advantage of LaTeX and {\emph{knitr}} options that allow us to separate our files into manageable pieces. The pieces are usually called child files\index{child files}, which are combined using a parent document\index{parent document}.

These methods can also be used when creating batch reports\index{batch reports}: documents that present results for a selected part of a data set. For example, a researcher may want to create individual reports of answers to survey questions from interviewees with a specific age. In this chapter we will rely on {\emph{knitr}} and shell scripts to create batch reports. 

\section{Planning large documents}

Before discussing the specifics of each of these methods, it's worth taking some time to carefully plan the structure of your child and parent documents.

\subsection{Planning theses and books}

Books and theses have a natural parent-child structure, i.e. they are single documents comprised of multiple chapters. They often include other child-like features such as title pages, bibliographies, figures, and appendices. You could include most of these features directly into one markup file. Clearly this file would become very large and unwieldy. It would be difficult to find one part or section to edit. If your presentation markup files are difficult to navigate, they are difficult to reproduce.  

\subsection{Planning batch reports}

\section{Combining Chapters}

We will cover three methods for including child documents into our parent documents. The first is very simple and uses the LaTeX command \texttt{\textbackslash{}input}\index{input}. The second uses {\emph{knitr}} and is slightly more complex, but is more flexibile. The final method is a special case of \texttt{\textbackslash{}input} that uses the command line program Pandoc \index{Pandoc} to convert and include child documents written in non-LaTeX markup languages. 

\subsection{Parent documents}

\paragraph{knitr global options}
{\emph{Knitr}} global chunk options\index{global chunk options} and package options\index{package options} should be set at the beginning of the parent document if you want them to apply to the entire presentation document. 

\subsection{Child documents}

\paragraph{Include child documents with input}

\paragraph{Include child documents with knitr}

\paragraph{Child documents in a different markup language}

Because {\emph{knitr}} is able to run not only R code but also Bash\index{Bash} command line programs, you can use the Pandoc \index{Pandoc} command line program to convert child documents that are in a different markup language into the primary markup language you are using for your document. If you have Pandoc installed on your computer,\footnote{Pandoc installation instructions can be found at: \url{http://johnmacfarlane.net/pandoc/installing.html}.} you can call it directly from your parent document by including your Pandoc commands in a code chunk with the \texttt{engine} option set to either \texttt{`bash'} or \texttt{'sh'}.\footnote{Alternatively you can run Pandoc in R using the {\tt{system}} command.} 

For example, the Stylistic Conventions part of this book is written in Markdown. The source file is called {\emph{StylisticConventions.md}} It was simply faster to write the list of conventions using the simpler Markdown syntax than LaTeX, which has a more complicated way of creating lists. However, I want to include this list in my LaTeX produced book. Pandoc can convert the Markdown document into a LaTeX file. This file can then be input into my main document with the LaTeX command \texttt{\textbackslash{}input}.

Imagine that my parent and {\emph{StylisticConventions.md}} documents are in the same directory. In the parent document I add a code chunk with the options {\tt{echo=FALSE}} and {\tt{results=`hide'}}. In this code chunk I add the following command to convert the Markdown syntax in {\emph{StylisticConventions.md}} to LaTeX and save it in a file called {\emph{StyleTemp.tex}}.

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{verbatim}
pandoc StylisticConventions.md -f markdown \
    -t latex -o StyleTemp.tex
\end{verbatim}
\end{kframe}
\end{knitrout}


\noindent The options {\tt{-f markdown}} and {\tt{-t latex}} tell Pandoc to convert {\emph{StylisticConventions.md}} from Markdown to LaTeX syntax. {\tt{-o StyleTemp.tex}} instructs Pandoc to save the resulting LaTeX markup to a new file called {\emph{StyleTemp.tex}}. 

I only need to include a backslash (\textbackslash{}) at the end of the first line because I wanted to split the code over two lines. The code wouldn't fit on this page otherwise. The backslash tells the shell not to treat the following line as a different line. Unlike in R, Bash only recognizes a command's arguments if they are on the same line as the command. After this code chunk we need to tell our parent document to include the converted text. To do this we follow the code chunk with the {\tt{\\input}} command like this:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\textbackslash{}input\{StyleTemp.tex\}
\end{alltt}
\end{kframe}
\end{knitrout}


\noindent Note that using this method to include a child document that needs to be knit will require extra steps not covered in this book.


\section{Creating Batch Reports}

\subsection{stich}
% Chapter Chapter 13 For Reproducible Research in R and RStudio
% Christopher Gandrud
% Created: 16/07/2012 05:45:03 pm CEST
% Updated: 14 October 2012




\chapter{Presenting on the Web and Beyond with Markdown/HTML}\label{MarkdownChapter}

\todo[inline]{This chapter is incomplete.}

\section{The Basics}

\subsection{Headings}

Headings in Markdown are extremely simple. To create a line in the topmost heading style--maybe a title--just place one hash mark (\texttt{\#}) at the beginning of the line. The second tier heading just gets two hashes (\texttt{\#\#}) and so on. You can also put the hash mark(s) at the end of the heading, but this is not necessary.

\subsection{Footnotes and bibliographies with MultiMarkdown}

\subsection{Math}

\subsection{Drawing figures with CSS}

\section{Presentations with \texttt{Slidify}}

\section{Simple webpages}

\subsection{RPubs}

\subsection{Hosting webpages with Dropbox}

\section{Reproducible websites}

\subsection{Blogging with Tumblr}

\subsection{Jekyll-Bootstrap and GitHub}

see \url{http://jfisher-usgs.github.com/r/2012/07/03/knitr-jekyll/}

\subsection{Jekyll and Github Pages}

\section{Using Markdown for non-HTML output with Pandoc}

Markdown syntax is very simple. So simple, you may be tempted to write many or all of your presentation documents in Markdown. This presents the obvious problem of how to convert your markdown documents to other markup languages if, for example, you want to create a LaTeX formatted PDF. As we saw in the previous chapter, Pandoc can help solve this problem. Pandoc is a command line program that can convert files written in Markdown, HTML, LaTeX, and a number of other markup languages\footnote{See the Pandoc website for more details: \url{http://johnmacfarlane.net/pandoc/}} to any of the other formats. 

%% Fill In Example with Fake Documents.

  
% Chapter Chapter 14 For Reproducible Research in R and RStudio
% Christopher Gandrud
% Created: 16/07/2012 05:45:03 pm CEST
% Updated: 14 October 2012




\chapter{Going Beyond the Book}\label{FinalChapter}

\todo[inline]{This chapter is incomplete.}

\section{Licensing Your Reproducible Research}

In the United States and many other countries research, including computer code made available via the internet is automatically given copyright protection. However, copyright protection works against the scientific goals of reproducible research, because work derived from the research falls under the original copyright protections \cite[36]{Stodden2009}. 

To solve this problem, some authors have suggest placing code under an open source software license like the GNU General Public License (GPL) \cite[]{Vandewalle2007}. Being designed to make software more freely available, they are not really adequate for making available the data, code, and other material needed to reproduce research findings in a way that enables scientific validation and knowledge growth \cite[see][]{Stodden2009}. 


% Include bibliotraphy
\bibliographystyle{apa}
\bibliography{/git_repositories/Rep-Res-Book/Source/rep-res-book.bib,/git_repositories/Rep-Res-Book/Source/rep-res-PackagesCited.bib}

% Include index
\clearpage
\printindex

\end{document}

